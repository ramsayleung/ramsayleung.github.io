<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>python on In Pursuit of Hubris</title><link>https://ramsayleung.github.io/tags/python/</link><description>Recent content in python on In Pursuit of Hubris</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 09 Apr 2017 00:00:00 +0800</lastBuildDate><atom:link href="https://ramsayleung.github.io/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>爬虫高效去重之布隆过滤器</title><link>https://ramsayleung.github.io/post/2017/bloom_filter/</link><pubDate>Sun, 09 Apr 2017 00:00:00 +0800</pubDate><guid>https://ramsayleung.github.io/post/2017/bloom_filter/</guid><description>笔者最近思考如何编写高效的爬虫; 而在编写高效爬虫的时候，有一个必需解决的问题就是： url 的去重，即如何判别 url 是否已经被爬取，如果被爬取，那就不要</description></item></channel></rss>