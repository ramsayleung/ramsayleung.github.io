<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Hbase on 过河卒</title>
    <link>https://ramsayleung.github.io/zh/tags/hbase/</link>
    <description>Recent content in Hbase on 过河卒</description>
    <image>
      <title>过河卒</title>
      <url>https://ramsayleung.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://ramsayleung.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.146.7</generator>
    <language>zh</language>
    <copyright>See this site&amp;rsquo;s source code here, licensed under GPLv3 ·</copyright>
    <lastBuildDate>Thu, 24 Feb 2022 22:58:14 +0800</lastBuildDate>
    <atom:link href="https://ramsayleung.github.io/zh/tags/hbase/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>记一次Hbase 宕机原因分析</title>
      <link>https://ramsayleung.github.io/zh/post/2018/hbase_crash/</link>
      <pubDate>Wed, 04 Apr 2018 19:54:00 +0800</pubDate>
      <guid>https://ramsayleung.github.io/zh/post/2018/hbase_crash/</guid>
      <description>&lt;h2 id=&#34;背景&#34;&gt;&lt;span class=&#34;section-num&#34;&gt;1&lt;/span&gt; 背景&lt;/h2&gt;
&lt;p&gt;在2018年4月4号早上，业务方反应Hbase 读超时，无法读取当前数据。然后发现测试环境的
Hbase region server 全部宕机，已经无可用Region Server. 因为公司的机器的Ip 和Host
不便在博文展示，所以我会用：&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h2 id="背景"><span class="section-num">1</span> 背景</h2>
<p>在2018年4月4号早上，业务方反应Hbase 读超时，无法读取当前数据。然后发现测试环境的
Hbase region server 全部宕机，已经无可用Region Server. 因为公司的机器的Ip 和Host
不便在博文展示，所以我会用：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">192.168.2.1: node-master
</span></span><span class="line"><span class="cl">192.168.2.2: node1
</span></span><span class="line"><span class="cl">192.168.2.3: node2
</span></span></code></pre></td></tr></table>
</div>
</div><p>来代替</p>
<h2 id="region-server-宕机原因分析"><span class="section-num">2</span> Region Server 宕机原因分析</h2>
<p>经查看日志，发现三台部署了Hbase 的服务器，分别是<code>node-master 192.168.2.1</code>, <code>node1 192.168.2.2</code>,=node2 192.168.2.3=. node1 机器在2018-03-13 14:47:55 收到了Shutdown Message, 停了Region Server. node-master这台机器在2018-03-20
10:13:07收到了Shutdown Message, 停掉了Region Server.</p>
<p>也就是说在3月下旬到昨天，Hbase 一直只有一台Region Server 在运行。而在昨天，2018-04-03 23:19:35, 剩下的最后一台机器也收到了Shutdown Message, 因此把剩下的最后一台Region Server 停掉，测试 环境的Hbase 全部下线。那么，为什么这三台服务器会收到Shutdown Message 呢？</p>
<h3 id="node1"><span class="section-num">2.1</span> node1</h3>
<p>先从 node1这台机器开始分析，关于 Region Server 退出的日志显示如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">13</span> <span class="mi">14</span><span class="p">:</span><span class="mi">47</span><span class="p">:</span><span class="mi">49</span><span class="p">,</span><span class="mi">665</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">main</span><span class="o">-</span><span class="n">SendThread</span><span class="p">(</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">:</span><span class="mi">2181</span><span class="p">)]</span> <span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Unable</span> <span class="n">to</span> <span class="n">reconnect</span> <span class="n">to</span> <span class="n">ZooKeeper</span> <span class="n">service</span><span class="p">,</span> <span class="n">session</span> <span class="mh">0x161d6c1ae910001</span> <span class="n">has</span> <span class="n">expired</span><span class="p">,</span> <span class="n">closing</span> <span class="n">socket</span> <span class="n">connection</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">13</span> <span class="mi">14</span><span class="p">:</span><span class="mi">47</span><span class="p">:</span><span class="mi">49</span><span class="p">,</span><span class="mi">706</span> <span class="n">FATAL</span> <span class="p">[</span><span class="n">main</span><span class="o">-</span><span class="n">EventThread</span><span class="p">]</span> <span class="n">regionserver</span><span class="o">.</span><span class="n">HRegionServer</span><span class="p">:</span> <span class="n">ABORTING</span> <span class="n">region</span> <span class="n">server</span> <span class="n">node1</span><span class="p">,</span><span class="mi">60020</span><span class="p">,</span><span class="mi">1519732610839</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">regionserver</span><span class="p">:</span><span class="mi">60020</span><span class="o">-</span><span class="mh">0x161d6c1ae910001</span><span class="p">,</span> <span class="n">quorum</span><span class="o">=</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">:</span><span class="mi">2181</span><span class="p">,</span><span class="n">node1</span><span class="p">:</span><span class="mi">2181</span><span class="p">,</span><span class="n">node2</span><span class="p">:</span><span class="mi">2181</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="n">baseZNode</span><span class="o">=/</span><span class="n">hbase</span> <span class="n">regionserver</span><span class="p">:</span><span class="mi">60020</span><span class="o">-</span><span class="mh">0x161d6c1ae910001</span> <span class="n">received</span> <span class="n">expired</span> <span class="n">from</span> <span class="n">ZooKeeper</span><span class="p">,</span> <span class="n">aborting</span>
</span></span><span class="line"><span class="cl"><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">zookeeper</span><span class="o">.</span><span class="n">KeeperException</span><span class="o">$</span><span class="n">SessionExpiredException</span><span class="p">:</span> <span class="n">KeeperErrorCode</span> <span class="o">=</span> <span class="n">Session</span> <span class="n">expired</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">zookeeper</span><span class="o">.</span><span class="n">ZooKeeperWatcher</span><span class="o">.</span><span class="n">connectionEvent</span><span class="p">(</span><span class="n">ZooKeeperWatcher</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">700</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">zookeeper</span><span class="o">.</span><span class="n">ZooKeeperWatcher</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">ZooKeeperWatcher</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">611</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="o">$</span><span class="n">EventThread</span><span class="o">.</span><span class="n">processEvent</span><span class="p">(</span><span class="n">ClientCnxn</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">522</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="o">$</span><span class="n">EventThread</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">ClientCnxn</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">498</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">13</span> <span class="mi">14</span><span class="p">:</span><span class="mi">47</span><span class="p">:</span><span class="mi">49</span><span class="p">,</span><span class="mi">718</span> <span class="n">FATAL</span> <span class="p">[</span><span class="n">main</span><span class="o">-</span><span class="n">EventThread</span><span class="p">]</span> <span class="n">regionserver</span><span class="o">.</span><span class="n">HRegionServer</span><span class="p">:</span> <span class="n">RegionServer</span> <span class="n">abort</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">loaded</span> <span class="n">coprocessors</span> <span class="n">are</span><span class="p">:</span> <span class="p">[</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">coprocessor</span><span class="o">.</span><span class="n">MultiRowMutationEndpoint</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">13</span> <span class="mi">14</span><span class="p">:</span><span class="mi">47</span><span class="p">:</span><span class="mi">50</span><span class="p">,</span><span class="mi">705</span> <span class="n">WARN</span>  <span class="p">[</span><span class="n">DataStreamer</span> <span class="k">for</span> <span class="n">file</span> <span class="o">/</span><span class="n">hbase</span><span class="o">-</span><span class="n">nemo</span><span class="o">/</span><span class="n">WALs</span><span class="o">/</span><span class="n">node1</span><span class="p">,</span><span class="mi">60020</span><span class="p">,</span><span class="mi">1519732610839</span><span class="o">/</span><span class="n">node1</span><span class="o">%</span><span class="mi">2</span><span class="n">C60020</span><span class="o">%</span><span class="mi">2</span><span class="n">C1519732610839</span><span class="o">.</span><span class="n">default</span><span class="o">.</span><span class="mi">1520922158622</span> <span class="n">block</span> <span class="n">BP</span><span class="o">-</span><span class="mi">1296874721</span><span class="o">-</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="o">-</span><span class="mi">1519712987003</span><span class="p">:</span><span class="n">blk_1073743994_3170</span><span class="p">]</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">DFSClient</span><span class="p">:</span> <span class="n">DataStreamer</span> <span class="n">Exception</span>
</span></span><span class="line"><span class="cl"><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">ipc</span><span class="o">.</span><span class="n">RemoteException</span><span class="p">(</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">server</span><span class="o">.</span><span class="n">namenode</span><span class="o">.</span><span class="n">LeaseExpiredException</span><span class="p">):</span>
</span></span><span class="line"><span class="cl"><span class="n">No</span> <span class="n">lease</span> <span class="n">on</span> <span class="o">/</span><span class="n">hbase</span><span class="o">-</span><span class="n">nemo</span><span class="o">/</span><span class="n">oldWALs</span><span class="o">/</span><span class="n">node1</span><span class="o">%</span><span class="mi">2</span><span class="n">C60020</span><span class="o">%</span><span class="mi">2</span><span class="n">C1519732610839</span><span class="o">.</span><span class="n">default</span><span class="o">.</span><span class="mi">1520922158622</span> <span class="p">(</span><span class="n">inode</span> <span class="mi">18837</span><span class="p">):</span>
</span></span><span class="line"><span class="cl"><span class="ne">File</span> <span class="n">is</span> <span class="ow">not</span> <span class="n">open</span> <span class="k">for</span> <span class="n">writing</span><span class="o">.</span> <span class="p">[</span><span class="n">Lease</span><span class="o">.</span>  <span class="n">Holder</span><span class="p">:</span> <span class="n">DFSClient_NONMAPREDUCE_551822027_1</span><span class="p">,</span> <span class="n">pendingcreates</span><span class="p">:</span> <span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">server</span><span class="o">.</span><span class="n">namenode</span><span class="o">.</span><span class="n">FSNamesystem</span><span class="o">.</span><span class="n">checkLease</span><span class="p">(</span><span class="n">FSNamesystem</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">3612</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">server</span><span class="o">.</span><span class="n">namenode</span><span class="o">.</span><span class="n">FSNamesystem</span><span class="o">.</span><span class="n">getAdditionalDatanode</span><span class="p">(</span><span class="n">FSNamesystem</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">3516</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">server</span><span class="o">.</span><span class="n">namenode</span><span class="o">.</span><span class="n">NameNodeRpcServer</span><span class="o">.</span><span class="n">getAdditionalDatanode</span><span class="p">(</span><span class="n">NameNodeRpcServer</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">711</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">server</span><span class="o">.</span><span class="n">namenode</span><span class="o">.</span><span class="n">AuthorizationProviderProxyClientProtocol</span><span class="o">.</span><span class="n">getAdditionalDatanode</span><span class="p">(</span><span class="n">AuthorizationProviderProxyClientProtocol</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">229</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">protocolPB</span><span class="o">.</span><span class="n">ClientNamenodeProtocolServerSideTranslatorPB</span><span class="o">.</span><span class="n">getAdditionalDatanode</span><span class="p">(</span><span class="n">ClientNamenodeProtocolServerSideTranslatorPB</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">508</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">protocol</span><span class="o">.</span><span class="n">proto</span><span class="o">.</span><span class="n">ClientNamenodeProtocolProtos</span><span class="o">$</span><span class="n">ClientNamenodeProtocol</span><span class="o">$</span><span class="mf">2.</span><span class="n">callBlockingMethod</span><span class="p">(</span><span class="n">ClientNamenodeProtocolProtos</span><span class="o">.</span><span class="n">java</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">ipc</span><span class="o">.</span><span class="n">ProtobufRpcEngine</span><span class="o">$</span><span class="n">Server</span><span class="o">$</span><span class="n">ProtoBufRpcInvoker</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">ProtobufRpcEngine</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">617</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">ipc</span><span class="o">.</span><span class="n">RPC</span><span class="o">$</span><span class="n">Server</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">RPC</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1073</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">ipc</span><span class="o">.</span><span class="n">Server</span><span class="o">$</span><span class="n">Handler</span><span class="o">$</span><span class="mf">1.</span><span class="n">run</span><span class="p">(</span><span class="n">Server</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">2086</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">ipc</span><span class="o">.</span><span class="n">Server</span><span class="o">$</span><span class="n">Handler</span><span class="o">$</span><span class="mf">1.</span><span class="n">run</span><span class="p">(</span><span class="n">Server</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">2082</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="n">security</span><span class="o">.</span><span class="n">AccessController</span><span class="o">.</span><span class="n">doPrivileged</span><span class="p">(</span><span class="n">Native</span> <span class="n">Method</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">javax</span><span class="o">.</span><span class="n">security</span><span class="o">.</span><span class="n">auth</span><span class="o">.</span><span class="n">Subject</span><span class="o">.</span><span class="n">doAs</span><span class="p">(</span><span class="n">Subject</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">422</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">security</span><span class="o">.</span><span class="n">UserGroupInformation</span><span class="o">.</span><span class="n">doAs</span><span class="p">(</span><span class="n">UserGroupInformation</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1693</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">ipc</span><span class="o">.</span><span class="n">Server</span><span class="o">$</span><span class="n">Handler</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">Server</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">2080</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">ipc</span><span class="o">.</span><span class="n">Client</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">Client</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1471</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">ipc</span><span class="o">.</span><span class="n">Client</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">Client</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1408</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">ipc</span><span class="o">.</span><span class="n">ProtobufRpcEngine</span><span class="o">$</span><span class="n">Invoker</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">ProtobufRpcEngine</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">230</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">com</span><span class="o">.</span><span class="n">sun</span><span class="o">.</span><span class="n">proxy</span><span class="o">.$</span><span class="n">Proxy16</span><span class="o">.</span><span class="n">getAdditionalDatanode</span><span class="p">(</span><span class="n">Unknown</span> <span class="n">Source</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">protocolPB</span><span class="o">.</span><span class="n">ClientNamenodeProtocolTranslatorPB</span><span class="o">.</span><span class="n">getAdditionalDatanode</span><span class="p">(</span><span class="n">ClientNamenodeProtocolTranslatorPB</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">429</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="n">reflect</span><span class="o">.</span><span class="n">NativeMethodAccessorImpl</span><span class="o">.</span><span class="n">invoke0</span><span class="p">(</span><span class="n">Native</span> <span class="n">Method</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="n">reflect</span><span class="o">.</span><span class="n">NativeMethodAccessorImpl</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">NativeMethodAccessorImpl</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">62</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="n">reflect</span><span class="o">.</span><span class="n">DelegatingMethodAccessorImpl</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">DelegatingMethodAccessorImpl</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">43</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">reflect</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">Method</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">498</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">retry</span><span class="o">.</span><span class="n">RetryInvocationHandler</span><span class="o">.</span><span class="n">invokeMethod</span><span class="p">(</span><span class="n">RetryInvocationHandler</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">256</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">retry</span><span class="o">.</span><span class="n">RetryInvocationHandler</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">RetryInvocationHandler</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">104</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">com</span><span class="o">.</span><span class="n">sun</span><span class="o">.</span><span class="n">proxy</span><span class="o">.$</span><span class="n">Proxy17</span><span class="o">.</span><span class="n">getAdditionalDatanode</span><span class="p">(</span><span class="n">Unknown</span> <span class="n">Source</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="n">reflect</span><span class="o">.</span><span class="n">NativeMethodAccessorImpl</span><span class="o">.</span><span class="n">invoke0</span><span class="p">(</span><span class="n">Native</span> <span class="n">Method</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="n">reflect</span><span class="o">.</span><span class="n">NativeMethodAccessorImpl</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">NativeMethodAccessorImpl</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">62</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">sun</span><span class="o">.</span><span class="n">reflect</span><span class="o">.</span><span class="n">DelegatingMethodAccessorImpl</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">DelegatingMethodAccessorImpl</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">43</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">reflect</span><span class="o">.</span><span class="n">Method</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">Method</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">498</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">HFileSystem</span><span class="o">$</span><span class="mf">1.</span><span class="n">invoke</span><span class="p">(</span><span class="n">HFileSystem</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">279</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">com</span><span class="o">.</span><span class="n">sun</span><span class="o">.</span><span class="n">proxy</span><span class="o">.$</span><span class="n">Proxy18</span><span class="o">.</span><span class="n">getAdditionalDatanode</span><span class="p">(</span><span class="n">Unknown</span> <span class="n">Source</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">addDatanode2ExistingPipeline</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1228</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">setupPipelineForAppendOrRecovery</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1404</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">processDatanodeError</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1119</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">622</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">13</span> <span class="mi">14</span><span class="p">:</span><span class="mi">47</span><span class="p">:</span><span class="mi">53</span><span class="p">,</span><span class="mi">803</span> <span class="n">FATAL</span> <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node1</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.2</span><span class="p">:</span><span class="mi">60020</span><span class="p">]</span> <span class="n">regionserver</span><span class="o">.</span><span class="n">HRegionServer</span><span class="p">:</span> <span class="n">ABORTING</span> <span class="n">region</span> <span class="n">server</span> <span class="n">node1</span><span class="p">,</span><span class="mi">60020</span><span class="p">,</span><span class="mi">1519732610839</span><span class="p">:</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">YouAreDeadException</span><span class="p">:</span> <span class="n">Server</span> <span class="n">REPORT</span> <span class="n">rejected</span><span class="p">;</span> <span class="n">currently</span> <span class="n">processing</span> <span class="n">node1</span><span class="p">,</span><span class="mi">60020</span><span class="p">,</span><span class="mi">1519732610839</span> <span class="n">as</span> <span class="n">dead</span> <span class="n">server</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>从 14:47:49 开始， Hbase 没法和 Zookeeper 通信，连接时间超时。翻查 Zookeeper 的日志，发现Zookeeper 的日志有如下内容：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">2018-03-13 14:47:46,926 [myid:1] - INFO  [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588]
</span></span><span class="line"><span class="cl">- Invalid session 0x161d6c1ae910002 for client /192.168.2.2:51611, probably expired
</span></span><span class="line"><span class="cl">2018-03-13 14:47:49,612 [myid:1] - INFO  [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588]
</span></span><span class="line"><span class="cl">- Invalid session 0x161d6c1ae910001 for client /192.168.2.2:51612, probably expired
</span></span></code></pre></td></tr></table>
</div>
</div><p>说明Hbase 和 ZooKeeper 的通信的确去了问题。连接出问题以后，集群就会认为 这个
Hbase 的节点出了故障，宕机，然后就把这个节点当作 <code>DeadNode</code>, 这个节点的
RegionServer 就下线了。</p>
<h3 id="node-master"><span class="section-num">2.2</span> node-master</h3>
<p>现在再来看看node-master这台机器的日志</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">19</span><span class="p">,</span><span class="mi">986</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">main</span><span class="o">-</span><span class="n">SendThread</span><span class="p">(</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">:</span><span class="mi">2181</span><span class="p">)]</span> <span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Unable</span> <span class="n">to</span> <span class="n">read</span> <span class="n">additional</span> <span class="n">data</span> <span class="n">from</span> <span class="n">server</span> <span class="n">sessionid</span> <span class="mh">0x361d65049260001</span><span class="p">,</span> <span class="n">likely</span> <span class="n">server</span> <span class="n">has</span> <span class="n">closed</span> <span class="n">socket</span><span class="p">,</span> <span class="n">closing</span> <span class="n">socket</span> <span class="n">connection</span> <span class="ow">and</span> <span class="n">attempting</span> <span class="n">reconnect</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span><span class="mi">841</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">main</span><span class="o">-</span><span class="n">SendThread</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span><span class="mi">2181</span><span class="p">)]</span> <span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Opening</span> <span class="n">socket</span> <span class="n">connection</span> <span class="n">to</span> <span class="n">server</span> <span class="n">node1</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.2</span><span class="p">:</span><span class="mf">2181.</span> <span class="n">Will</span> <span class="ow">not</span> <span class="n">attempt</span> <span class="n">to</span> <span class="n">authenticate</span> <span class="n">using</span> <span class="n">SASL</span> <span class="p">(</span><span class="n">unknown</span> <span class="n">error</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">43</span><span class="p">,</span><span class="mi">747</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">60020</span><span class="o">-</span><span class="n">SendThread</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span><span class="mi">2181</span><span class="p">)]</span> <span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Client</span> <span class="n">session</span> <span class="n">timed</span> <span class="n">out</span><span class="p">,</span> <span class="n">have</span> <span class="ow">not</span> <span class="n">heard</span> <span class="n">from</span> <span class="n">server</span> <span class="ow">in</span> <span class="mi">60019</span><span class="n">ms</span> <span class="k">for</span> <span class="n">sessionid</span> <span class="mh">0x161d65049590000</span><span class="p">,</span> <span class="n">closing</span> <span class="n">socket</span> <span class="n">connection</span> <span class="ow">and</span> <span class="n">attempting</span> <span class="n">reconnect</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">44</span><span class="p">,</span><span class="mi">574</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">60020</span><span class="o">-</span><span class="n">SendThread</span><span class="p">(</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">:</span><span class="mi">2181</span><span class="p">)]</span> <span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Opening</span> <span class="n">socket</span> <span class="n">connection</span> <span class="n">to</span> <span class="n">server</span> <span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mf">2181.</span> <span class="n">Will</span> <span class="ow">not</span> <span class="n">attempt</span> <span class="n">to</span> <span class="n">authenticate</span> <span class="n">using</span> <span class="n">SASL</span> <span class="p">(</span><span class="n">unknown</span> <span class="n">error</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">44</span><span class="p">,</span><span class="mi">575</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">60020</span><span class="o">-</span><span class="n">SendThread</span><span class="p">(</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">:</span><span class="mi">2181</span><span class="p">)]</span> <span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Socket</span> <span class="n">connection</span> <span class="n">established</span><span class="p">,</span> <span class="n">initiating</span> <span class="n">session</span><span class="p">,</span> <span class="n">client</span><span class="p">:</span> <span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">58042</span><span class="p">,</span> <span class="n">server</span><span class="p">:</span> <span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">2181</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">44</span><span class="p">,</span><span class="mi">577</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">60020</span><span class="o">-</span><span class="n">SendThread</span><span class="p">(</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">:</span><span class="mi">2181</span><span class="p">)]</span> <span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Session</span> <span class="n">establishment</span> <span class="n">complete</span> <span class="n">on</span> <span class="n">server</span> <span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">2181</span><span class="p">,</span> <span class="n">sessionid</span> <span class="o">=</span> <span class="mh">0x161d65049590000</span><span class="p">,</span> <span class="n">negotiated</span> <span class="n">timeout</span> <span class="o">=</span> <span class="mi">90000</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">49</span><span class="p">,</span><span class="mi">625</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">main</span><span class="o">-</span><span class="n">SendThread</span><span class="p">(</span><span class="n">node1</span><span class="p">:</span><span class="mi">2181</span><span class="p">)]</span> <span class="n">zookeeper</span><span class="o">.</span><span class="n">ClientCnxn</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Socket</span> <span class="n">connection</span> <span class="n">established</span><span class="p">,</span> <span class="n">initiating</span> <span class="n">session</span><span class="p">,</span> <span class="n">client</span><span class="p">:</span> <span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">46815</span><span class="p">,</span> <span class="n">server</span><span class="p">:</span> <span class="n">node1</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.2</span><span class="p">:</span><span class="mi">2181</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">53</span><span class="p">,</span><span class="mi">258</span> <span class="n">WARN</span>  <span class="p">[</span><span class="n">ResponseProcessor</span> <span class="k">for</span> <span class="n">block</span> <span class="n">BP</span><span class="o">-</span><span class="mi">1296874721</span><span class="o">-</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="o">-</span><span class="mi">1519712987003</span><span class="p">:</span>
</span></span><span class="line"><span class="cl"><span class="n">blk_1073747108_6286</span><span class="p">]</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">DFSClient</span><span class="p">:</span> <span class="n">Slow</span> <span class="n">ReadProcessor</span> <span class="n">read</span> <span class="n">fields</span> <span class="n">took</span> <span class="mi">70070</span><span class="n">ms</span> <span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mi">30000</span><span class="n">ms</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">ack</span><span class="p">:</span> <span class="n">seqno</span><span class="p">:</span> <span class="o">-</span><span class="mi">2</span> <span class="n">reply</span><span class="p">:</span> <span class="mi">0</span> <span class="n">reply</span><span class="p">:</span> <span class="mi">1</span> <span class="n">downstreamAckTimeNanos</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">targets</span><span class="p">:</span> <span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.2</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">4</span><span class="n">eb97418</span><span class="o">-</span><span class="n">f0a1</span><span class="o">-</span><span class="mi">45</span><span class="n">a7</span><span class="o">-</span><span class="n">b335</span><span class="o">-</span><span class="mi">83</span><span class="n">f77e4d6a7b</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">53</span><span class="p">,</span><span class="mi">259</span> <span class="n">WARN</span>  <span class="p">[</span><span class="n">ResponseProcessor</span> <span class="k">for</span> <span class="n">block</span> <span class="n">BP</span><span class="o">-</span><span class="mi">1296874721</span><span class="o">-</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="o">-</span><span class="mi">1519712987003</span><span class="p">:</span><span class="n">blk_1073747108_6286</span><span class="p">]</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">DFSClient</span><span class="p">:</span> <span class="n">DFSOutputStream</span> <span class="n">ResponseProcessor</span> <span class="n">exception</span>  <span class="k">for</span> <span class="n">block</span> <span class="n">BP</span><span class="o">-</span><span class="mi">1296874721</span><span class="o">-</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="o">-</span><span class="mi">1519712987003</span><span class="p">:</span><span class="n">blk_1073747108_6286</span>
</span></span><span class="line"><span class="cl"><span class="n">java</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">IOException</span><span class="p">:</span> <span class="n">Bad</span> <span class="n">response</span> <span class="n">ERROR</span> <span class="k">for</span> <span class="n">block</span> <span class="n">BP</span><span class="o">-</span><span class="mi">1296874721</span><span class="o">-</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="o">-</span><span class="mi">1519712987003</span><span class="p">:</span><span class="n">blk_1073747108_6286</span> <span class="n">from</span> <span class="n">datanode</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.2</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">4</span><span class="n">eb97418</span><span class="o">-</span><span class="n">f0a1</span><span class="o">-</span><span class="mi">45</span><span class="n">a7</span><span class="o">-</span><span class="n">b335</span><span class="o">-</span><span class="mi">83</span><span class="n">f77e4d6a7b</span><span class="p">,</span><span class="n">DISK</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">$</span><span class="n">ResponseProcessor</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1002</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">53</span><span class="p">,</span><span class="mi">259</span> <span class="n">WARN</span>  <span class="p">[</span><span class="n">DataStreamer</span> <span class="k">for</span> <span class="n">file</span> <span class="o">/</span><span class="n">hbase</span><span class="o">-</span><span class="n">nemo</span><span class="o">/</span><span class="n">WALs</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">,</span><span class="mi">60020</span><span class="p">,</span><span class="mi">1519720160721</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">%</span><span class="mi">2</span><span class="n">C60020</span><span class="o">%</span><span class="mi">2</span><span class="n">C1519720160721</span><span class="o">.</span><span class="n">default</span><span class="o">.</span><span class="mi">1521509628323</span> <span class="n">block</span> <span class="n">BP</span><span class="o">-</span><span class="mi">1296874721</span><span class="o">-</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="o">-</span><span class="mi">1519712987003</span><span class="p">:</span><span class="n">blk_1073747108_6286</span><span class="p">]</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">DFSClient</span><span class="p">:</span> <span class="n">Error</span> <span class="n">Recovery</span> <span class="k">for</span> <span class="n">block</span> <span class="n">BP</span><span class="o">-</span><span class="mi">1296874721</span><span class="o">-</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="o">-</span><span class="mi">1519712987003</span><span class="p">:</span><span class="n">blk_1073747108_6286</span> <span class="ow">in</span> <span class="n">pipeline</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.2</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">4</span><span class="n">eb97418</span><span class="o">-</span><span class="n">f0a1</span><span class="o">-</span><span class="mi">45</span><span class="n">a7</span><span class="o">-</span><span class="n">b335</span><span class="o">-</span><span class="mi">83</span><span class="n">f77e4d6a7b</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]:</span> <span class="n">bad</span> <span class="n">datanode</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.2</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">4</span><span class="n">eb97418</span><span class="o">-</span><span class="n">f0a1</span><span class="o">-</span><span class="mi">45</span><span class="n">a7</span><span class="o">-</span><span class="n">b335</span><span class="o">-</span><span class="mi">83</span><span class="n">f77e4d6a7b</span><span class="p">,</span><span class="n">DISK</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">53</span><span class="p">,</span><span class="mi">264</span> <span class="n">WARN</span>  <span class="p">[</span><span class="n">DataStreamer</span> <span class="k">for</span> <span class="n">file</span> <span class="o">/</span><span class="n">hbase</span><span class="o">-</span><span class="n">nemo</span><span class="o">/</span><span class="n">WALs</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">,</span><span class="mi">60020</span><span class="p">,</span><span class="mi">1519720160721</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">%</span><span class="mi">2</span><span class="n">C60020</span><span class="o">%</span><span class="mi">2</span><span class="n">C1519720160721</span><span class="o">.</span><span class="n">default</span><span class="o">.</span><span class="mi">1521509628323</span> <span class="n">block</span> <span class="n">BP</span><span class="o">-</span><span class="mi">1296874721</span><span class="o">-</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="o">-</span><span class="mi">1519712987003</span><span class="p">:</span><span class="n">blk_1073747108_6286</span><span class="p">]</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">DFSClient</span><span class="p">:</span> <span class="n">DataStreamer</span> <span class="n">Exception</span>
</span></span><span class="line"><span class="cl"><span class="n">java</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">IOException</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">to</span> <span class="n">replace</span> <span class="n">a</span> <span class="n">bad</span> <span class="n">datanode</span> <span class="n">on</span> <span class="n">the</span> <span class="n">existing</span> <span class="n">pipeline</span> <span class="n">due</span> <span class="n">to</span> <span class="n">no</span> <span class="n">more</span> <span class="n">good</span> <span class="n">datanodes</span> <span class="n">being</span> <span class="n">available</span> <span class="n">to</span> <span class="n">try</span><span class="o">.</span> <span class="p">(</span><span class="n">Nodes</span><span class="p">:</span> <span class="n">current</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]],</span> <span class="n">original</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]])</span><span class="o">.</span> <span class="n">The</span> <span class="n">current</span> <span class="n">failed</span> <span class="n">datanode</span> <span class="n">replacement</span> <span class="n">policy</span> <span class="n">is</span> <span class="n">DEFAULT</span><span class="p">,</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">client</span> <span class="n">may</span> <span class="n">configure</span> <span class="n">this</span> <span class="n">via</span> <span class="s1">&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">configuration</span><span class="o">.</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">findNewDatanode</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1162</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">addDatanode2ExistingPipeline</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1236</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">setupPipelineForAppendOrRecovery</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1404</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">processDatanodeError</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1119</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">622</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">53</span><span class="p">,</span><span class="mi">265</span> <span class="n">WARN</span>  <span class="p">[</span><span class="n">sync</span><span class="o">.</span><span class="mi">4</span><span class="p">]</span> <span class="n">hdfs</span><span class="o">.</span><span class="n">DFSClient</span><span class="p">:</span> <span class="n">Error</span> <span class="k">while</span> <span class="n">syncing</span>
</span></span><span class="line"><span class="cl"><span class="n">java</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">IOException</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">to</span> <span class="n">replace</span> <span class="n">a</span> <span class="n">bad</span> <span class="n">datanode</span> <span class="n">on</span> <span class="n">the</span> <span class="n">existing</span> <span class="n">pipeline</span> <span class="n">due</span> <span class="n">to</span> <span class="n">no</span> <span class="n">more</span> <span class="n">good</span> <span class="n">datanodes</span> <span class="n">being</span> <span class="n">available</span> <span class="n">to</span> <span class="n">try</span><span class="o">.</span> <span class="p">(</span><span class="n">Nodes</span><span class="p">:</span> <span class="n">current</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]],</span> <span class="n">original</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]])</span><span class="o">.</span> <span class="n">The</span> <span class="n">current</span> <span class="n">failed</span> <span class="n">datanode</span> <span class="n">replacement</span> <span class="n">policy</span> <span class="n">is</span> <span class="n">DEFAULT</span><span class="p">,</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">client</span> <span class="n">may</span> <span class="n">configure</span> <span class="n">this</span> <span class="n">via</span> <span class="s1">&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">configuration</span><span class="o">.</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">findNewDatanode</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1162</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">addDatanode2ExistingPipeline</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1236</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">setupPipelineForAppendOrRecovery</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1404</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">processDatanodeError</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1119</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">622</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">53</span><span class="p">,</span><span class="mi">266</span> <span class="n">ERROR</span> <span class="p">[</span><span class="n">sync</span><span class="o">.</span><span class="mi">4</span><span class="p">]</span> <span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="p">:</span> <span class="n">Error</span> <span class="n">syncing</span><span class="p">,</span> <span class="n">request</span> <span class="n">close</span> <span class="n">of</span> <span class="n">WAL</span>
</span></span><span class="line"><span class="cl"><span class="n">java</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">IOException</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">to</span> <span class="n">replace</span> <span class="n">a</span> <span class="n">bad</span> <span class="n">datanode</span> <span class="n">on</span> <span class="n">the</span> <span class="n">existing</span> <span class="n">pipeline</span> <span class="n">due</span> <span class="n">to</span> <span class="n">no</span> <span class="n">more</span> <span class="n">good</span> <span class="n">datanodes</span> <span class="n">being</span> <span class="n">available</span> <span class="n">to</span> <span class="n">try</span><span class="o">.</span> <span class="p">(</span><span class="n">Nodes</span><span class="p">:</span> <span class="n">current</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]],</span> <span class="n">original</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]])</span><span class="o">.</span> <span class="n">The</span> <span class="n">current</span> <span class="n">failed</span> <span class="n">datanode</span> <span class="n">replacement</span> <span class="n">policy</span> <span class="n">is</span> <span class="n">DEFAULT</span><span class="p">,</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">client</span> <span class="n">may</span> <span class="n">configure</span> <span class="n">this</span> <span class="n">via</span> <span class="s1">&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">configuration</span><span class="o">.</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">findNewDatanode</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1162</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">addDatanode2ExistingPipeline</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1236</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">setupPipelineForAppendOrRecovery</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1404</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">processDatanodeError</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1119</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">622</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">12</span><span class="p">:</span><span class="mi">53</span><span class="p">,</span><span class="mi">266</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">sync</span><span class="o">.</span><span class="mi">4</span><span class="p">]</span> <span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="p">:</span> <span class="n">Slow</span> <span class="n">sync</span> <span class="n">cost</span><span class="p">:</span> <span class="mi">474</span> <span class="n">ms</span><span class="p">,</span> <span class="n">current</span> <span class="n">pipeline</span><span class="p">:</span> <span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">13</span><span class="p">:</span><span class="mi">05</span><span class="p">,</span><span class="mi">816</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mf">60020.</span><span class="n">logRoller</span><span class="p">]</span> <span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="p">:</span> <span class="n">Slow</span> <span class="n">sync</span> <span class="n">cost</span><span class="p">:</span> <span class="mi">12546</span> <span class="n">ms</span><span class="p">,</span> <span class="n">current</span> <span class="n">pipeline</span><span class="p">:</span> <span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">13</span><span class="p">:</span><span class="mi">05</span><span class="p">,</span><span class="mi">817</span> <span class="n">ERROR</span> <span class="p">[</span><span class="n">sync</span><span class="o">.</span><span class="mi">0</span><span class="p">]</span> <span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="p">:</span> <span class="n">Error</span> <span class="n">syncing</span><span class="p">,</span> <span class="n">request</span> <span class="n">close</span> <span class="n">of</span> <span class="n">WAL</span>
</span></span><span class="line"><span class="cl"><span class="n">java</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">IOException</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">to</span> <span class="n">replace</span> <span class="n">a</span> <span class="n">bad</span> <span class="n">datanode</span> <span class="n">on</span> <span class="n">the</span> <span class="n">existing</span> <span class="n">pipeline</span> <span class="n">due</span> <span class="n">to</span> <span class="n">no</span> <span class="n">more</span> <span class="n">good</span> <span class="n">datanodes</span> <span class="n">being</span> <span class="n">available</span> <span class="n">to</span> <span class="n">try</span><span class="o">.</span> <span class="p">(</span><span class="n">Nodes</span><span class="p">:</span> <span class="n">current</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]],</span> <span class="n">original</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]])</span><span class="o">.</span> <span class="n">The</span> <span class="n">current</span> <span class="n">failed</span> <span class="n">datanode</span> <span class="n">replacement</span> <span class="n">policy</span> <span class="n">is</span> <span class="n">DEFAULT</span><span class="p">,</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">client</span> <span class="n">may</span> <span class="n">configure</span> <span class="n">this</span> <span class="n">via</span> <span class="s1">&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">configuration</span><span class="o">.</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">findNewDatanode</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1162</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">addDatanode2ExistingPipeline</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1236</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">setupPipelineForAppendOrRecovery</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1404</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">processDatanodeError</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1119</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">622</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">13</span><span class="p">:</span><span class="mi">05</span><span class="p">,</span><span class="mi">817</span> <span class="n">ERROR</span> <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mf">60020.</span><span class="n">logRoller</span><span class="p">]</span> <span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">close</span> <span class="n">of</span> <span class="n">WAL</span> <span class="n">writer</span> <span class="n">hdfs</span><span class="p">:</span><span class="o">//</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">:</span><span class="mi">19000</span><span class="o">/</span><span class="n">hbase</span><span class="o">-</span><span class="n">nemo</span><span class="o">/</span><span class="n">WALs</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">,</span><span class="mi">60020</span><span class="p">,</span><span class="mi">1519720160721</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">%</span><span class="mi">2</span><span class="n">C60020</span><span class="o">%</span><span class="mi">2</span><span class="n">C1519720160721</span><span class="o">.</span><span class="n">default</span><span class="o">.</span><span class="mi">1521509628323</span><span class="p">,</span> <span class="n">unflushedEntries</span><span class="o">=</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FailedSyncBeforeLogCloseException</span><span class="p">:</span> <span class="n">java</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">IOException</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">to</span> <span class="n">replace</span> <span class="n">a</span> <span class="n">bad</span> <span class="n">datanode</span> <span class="n">on</span> <span class="n">the</span> <span class="n">existing</span> <span class="n">pipeline</span> <span class="n">due</span> <span class="n">to</span> <span class="n">no</span> <span class="n">more</span> <span class="n">good</span> <span class="n">datanodes</span> <span class="n">being</span> <span class="n">available</span> <span class="n">to</span> <span class="n">try</span><span class="o">.</span> <span class="p">(</span><span class="n">Nodes</span><span class="p">:</span> <span class="n">current</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]],</span> <span class="n">original</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]])</span><span class="o">.</span> <span class="n">The</span> <span class="n">current</span> <span class="n">failed</span> <span class="n">datanode</span> <span class="n">replacement</span> <span class="n">policy</span> <span class="n">is</span> <span class="n">DEFAULT</span><span class="p">,</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">client</span> <span class="n">may</span> <span class="n">configure</span> <span class="n">this</span> <span class="n">via</span> <span class="s1">&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">configuration</span><span class="o">.</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="o">$</span><span class="n">SafePointZigZagLatch</span><span class="o">.</span><span class="n">waitSafePoint</span><span class="p">(</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1615</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">replaceWriter</span><span class="p">(</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">833</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">rollWriter</span><span class="p">(</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">699</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">LogRoller</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">LogRoller</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">148</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">Thread</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="ne">Thread</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">748</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">Caused</span> <span class="n">by</span><span class="p">:</span> <span class="n">java</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">IOException</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">to</span> <span class="n">replace</span> <span class="n">a</span> <span class="n">bad</span> <span class="n">datanode</span> <span class="n">on</span> <span class="n">the</span> <span class="n">existing</span> <span class="n">pipeline</span> <span class="n">due</span> <span class="n">to</span> <span class="n">no</span> <span class="n">more</span> <span class="n">good</span> <span class="n">datanodes</span> <span class="n">being</span> <span class="n">available</span> <span class="n">to</span> <span class="n">try</span><span class="o">.</span>
</span></span><span class="line"><span class="cl"><span class="p">(</span><span class="n">Nodes</span><span class="p">:</span> <span class="n">current</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl"><span class="n">original</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span>
</span></span><span class="line"><span class="cl"><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]])</span><span class="o">.</span>
</span></span><span class="line"><span class="cl"><span class="n">The</span> <span class="n">current</span> <span class="n">failed</span> <span class="n">datanode</span> <span class="n">replacement</span> <span class="n">policy</span> <span class="n">is</span> <span class="n">DEFAULT</span><span class="p">,</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">client</span> <span class="n">may</span> <span class="n">configure</span> <span class="n">this</span>
</span></span><span class="line"><span class="cl"><span class="n">via</span> <span class="s1">&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">configuration</span><span class="o">.</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">findNewDatanode</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1162</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">addDatanode2ExistingPipeline</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1236</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">setupPipelineForAppendOrRecovery</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1404</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">processDatanodeError</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1119</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">622</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">13</span><span class="p">:</span><span class="mi">05</span><span class="p">,</span><span class="mi">818</span> <span class="n">FATAL</span> <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mf">60020.</span><span class="n">logRoller</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">regionserver</span><span class="o">.</span><span class="n">HRegionServer</span><span class="p">:</span> <span class="n">ABORTING</span> <span class="n">region</span> <span class="n">server</span> <span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">,</span><span class="mi">60020</span><span class="p">,</span><span class="mi">1519720160721</span><span class="p">:</span> <span class="n">Failed</span> <span class="nb">log</span> <span class="n">close</span> <span class="ow">in</span> <span class="nb">log</span> <span class="n">roller</span>
</span></span><span class="line"><span class="cl"><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FailedLogCloseException</span><span class="p">:</span> <span class="n">hdfs</span><span class="p">:</span><span class="o">//</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">:</span><span class="mi">19000</span><span class="o">/</span><span class="n">hbase</span><span class="o">-</span><span class="n">nemo</span><span class="o">/</span><span class="n">WALs</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="p">,</span><span class="mi">60020</span><span class="p">,</span><span class="mi">1519720160721</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">%</span><span class="mi">2</span><span class="n">C60020</span><span class="o">%</span><span class="mi">2</span><span class="n">C1519720160721</span><span class="o">.</span><span class="n">default</span><span class="o">.</span><span class="mi">1521509628323</span><span class="p">,</span> <span class="n">unflushedEntries</span><span class="o">=</span><span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">replaceWriter</span><span class="p">(</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">882</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">rollWriter</span><span class="p">(</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">699</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">LogRoller</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">LogRoller</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">148</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">java</span><span class="o">.</span><span class="n">lang</span><span class="o">.</span><span class="n">Thread</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="ne">Thread</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">748</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">Caused</span> <span class="n">by</span><span class="p">:</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FailedSyncBeforeLogCloseException</span><span class="p">:</span> <span class="n">java</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">IOException</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">to</span> <span class="n">replace</span> <span class="n">a</span> <span class="n">bad</span> <span class="n">datanode</span> <span class="n">on</span> <span class="n">the</span> <span class="n">existing</span> <span class="n">pipeline</span> <span class="n">due</span> <span class="n">to</span> <span class="n">no</span> <span class="n">more</span> <span class="n">good</span> <span class="n">datanodes</span> <span class="n">being</span> <span class="n">available</span> <span class="n">to</span> <span class="n">try</span><span class="o">.</span> <span class="p">(</span><span class="n">Nodes</span><span class="p">:</span> <span class="n">current</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]],</span> <span class="n">original</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]])</span><span class="o">.</span> <span class="n">The</span> <span class="n">current</span> <span class="n">failed</span> <span class="n">datanode</span> <span class="n">replacement</span> <span class="n">policy</span> <span class="n">is</span> <span class="n">DEFAULT</span><span class="p">,</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">client</span> <span class="n">may</span> <span class="n">configure</span> <span class="n">this</span> <span class="n">via</span> <span class="s1">&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">configuration</span><span class="o">.</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="o">$</span><span class="n">SafePointZigZagLatch</span><span class="o">.</span><span class="n">waitSafePoint</span><span class="p">(</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1615</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hbase</span><span class="o">.</span><span class="n">regionserver</span><span class="o">.</span><span class="n">wal</span><span class="o">.</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">replaceWriter</span><span class="p">(</span><span class="n">FSHLog</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">833</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="o">...</span> <span class="mi">3</span> <span class="n">more</span>
</span></span><span class="line"><span class="cl"><span class="n">Caused</span> <span class="n">by</span><span class="p">:</span> <span class="n">java</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">IOException</span><span class="p">:</span> <span class="n">Failed</span> <span class="n">to</span> <span class="n">replace</span> <span class="n">a</span> <span class="n">bad</span> <span class="n">datanode</span> <span class="n">on</span> <span class="n">the</span> <span class="n">existing</span> <span class="n">pipeline</span> <span class="n">due</span> <span class="n">to</span> <span class="n">no</span> <span class="n">more</span> <span class="n">good</span> <span class="n">datanodes</span> <span class="n">being</span> <span class="n">available</span> <span class="n">to</span> <span class="n">try</span><span class="o">.</span> <span class="p">(</span><span class="n">Nodes</span><span class="p">:</span> <span class="n">current</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]],</span> <span class="n">original</span><span class="o">=</span><span class="p">[</span><span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="mi">84998</span><span class="n">b22</span><span class="o">-</span><span class="mi">8294</span><span class="o">-</span><span class="mi">44</span><span class="n">ed</span><span class="o">-</span><span class="mi">90</span><span class="n">fd</span><span class="o">-</span><span class="mi">9</span><span class="n">c1a78d0f558</span><span class="p">,</span><span class="n">DISK</span><span class="p">],</span> <span class="n">DatanodeInfoWithStorage</span><span class="p">[</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.3</span><span class="p">:</span><span class="mi">50010</span><span class="p">,</span><span class="n">DS</span><span class="o">-</span><span class="n">d94668c9</span><span class="o">-</span><span class="mi">66</span><span class="n">f4</span><span class="o">-</span><span class="mi">40</span><span class="n">f6</span><span class="o">-</span><span class="n">b38f</span><span class="o">-</span><span class="mi">83</span><span class="n">f14b26c2b4</span><span class="p">,</span><span class="n">DISK</span><span class="p">]])</span><span class="o">.</span> <span class="n">The</span> <span class="n">current</span> <span class="n">failed</span> <span class="n">datanode</span> <span class="n">replacement</span> <span class="n">policy</span> <span class="n">is</span> <span class="n">DEFAULT</span><span class="p">,</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">client</span> <span class="n">may</span> <span class="n">configure</span> <span class="n">this</span> <span class="n">via</span> <span class="s1">&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">configuration</span><span class="o">.</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">findNewDatanode</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1162</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">addDatanode2ExistingPipeline</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1236</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">setupPipelineForAppendOrRecovery</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1404</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">processDatanodeError</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">1119</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">at</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">hadoop</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">DFSOutputStream</span><span class="o">$</span><span class="n">DataStreamer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">DFSOutputStream</span><span class="o">.</span><span class="n">java</span><span class="p">:</span><span class="mi">622</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">13</span><span class="p">:</span><span class="mi">05</span><span class="p">,</span><span class="mi">818</span> <span class="n">FATAL</span> <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mf">60020.</span><span class="n">logRoller</span><span class="p">]</span> <span class="n">regionserver</span><span class="o">.</span><span class="n">HRegionServer</span><span class="p">:</span> <span class="n">RegionServer</span> <span class="n">abort</span><span class="p">:</span> <span class="n">loaded</span> <span class="n">coprocessors</span> <span class="n">are</span><span class="p">:</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="mi">2018</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">20</span> <span class="mi">10</span><span class="p">:</span><span class="mi">13</span><span class="p">:</span><span class="mi">05</span><span class="p">,</span><span class="mi">997</span> <span class="n">INFO</span>  <span class="p">[</span><span class="n">regionserver</span><span class="o">/</span><span class="n">node</span><span class="o">-</span><span class="n">master</span><span class="o">/</span><span class="mf">192.168</span><span class="o">.</span><span class="mf">2.1</span><span class="p">:</span><span class="mf">60020.</span><span class="n">logRoller</span><span class="p">]</span> <span class="n">regionserver</span><span class="o">.</span><span class="n">HRegionServer</span><span class="p">:</span> <span class="n">Dump</span> <span class="n">of</span> <span class="n">metrics</span> <span class="n">as</span> <span class="n">JSON</span> <span class="n">on</span> <span class="n">abort</span><span class="p">:</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>从上面的日志可以看到 node-master与node1机器通信，获取node1 的响应失败，认为node1 是 bad DataNode，接着集群想要把出现问题的DataNode 下掉，却发现没有多余DataNode 来替换， 紧接着在Syncing 时出错，关闭 WAL 失败, 最后就停掉了Region Server. 比较关键的时机如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">2018-03-20 10:12:53,265 WARN  [sync.4] hdfs.DFSClient: Error while syncing
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">2018-03-20 10:12:53,266 ERROR [sync.4] wal.FSHLog: Error syncing, request close of WAL
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">2018-03-20 10:13:05,817 ERROR [sync.0] wal.FSHLog: Error syncing, request close of WAL
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">2018-03-20 10:13:06,397 ERROR [regionserver/node-master/192.168.2.1:60020] regionserver.HRegionServer: Shutdown / close of WAL failed: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via &#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39; in its configuration.
</span></span></code></pre></td></tr></table>
</div>
</div><p>期间HDFS 同步出错，尝试关闭WAL, 失败。失败的原因是无法用健康的节点替换出了问题的节点， 应该是健康的节点数太少了。最后在多次尝试关闭WAL都因为IOException 失败之后，
RegionServer 下线。只是为什么尝试关闭WAL 失败需要关闭Region Server 依然存疑。</p>
<h3 id="node2"><span class="section-num">2.3</span> node2</h3>
<p>node2 是Hbase 集群最后一台机器，当node2 倒下了，Hbase 就真的完全宕机了。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">2018-04-03 23:19:33,472 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.LogRoller: Aborting
</span></span><span class="line"><span class="cl">java.io.IOException: cannot get log writer
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:365)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:724)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:689)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148)
</span></span><span class="line"><span class="cl">    at java.lang.Thread.run(Thread.java:748)
</span></span><span class="line"><span class="cl">Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/hbase-nemo/WALs/node2,60020,1519732668326/node2%2C60020%2C1519732668326.default.1522768773233. Name node is in safe mode.
</span></span><span class="line"><span class="cl">Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use &#34;hdfs dfsadmin -safemode leave&#34; to turn safe mode off.
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1418)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2674)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2561)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:593)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.create(AuthorizationProviderProxyClientProtocol.java:111)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:393)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
</span></span><span class="line"><span class="cl">    at java.security.AccessController.doPrivileged(Native Method)
</span></span><span class="line"><span class="cl">    at javax.security.auth.Subject.doAs(Subject.java:422)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Client.call(Client.java:1471)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Client.call(Client.java:1408)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
</span></span><span class="line"><span class="cl">    at com.sun.proxy.$Proxy16.create(Unknown Source)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
</span></span><span class="line"><span class="cl">    at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
</span></span><span class="line"><span class="cl">    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span></span><span class="line"><span class="cl">    at java.lang.reflect.Method.invoke(Method.java:498)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
</span></span><span class="line"><span class="cl">    at com.sun.proxy.$Proxy17.create(Unknown Source)
</span></span><span class="line"><span class="cl">    at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
</span></span><span class="line"><span class="cl">    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span></span><span class="line"><span class="cl">    at java.lang.reflect.Method.invoke(Method.java:498)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
</span></span><span class="line"><span class="cl">    at com.sun.proxy.$Proxy18.create(Unknown Source)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1897)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1738)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1698)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:450)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:446)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive(DistributedFileSystem.java:446)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1124)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1100)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.init(ProtobufLogWriter.java:90)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:361)
</span></span><span class="line"><span class="cl">    ... 4 more
</span></span><span class="line"><span class="cl">2018-04-03 23:19:33,501 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.HRegionServer: ABORTING region server node2,60020,1519732668326: IOE in log roller
</span></span><span class="line"><span class="cl">java.io.IOException: cannot get log writer
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:365)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:724)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:689)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148)
</span></span><span class="line"><span class="cl">    at java.lang.Thread.run(Thread.java:748)
</span></span><span class="line"><span class="cl">Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/hbase-nemo/WALs/node2,60020,1519732668326/node2%2C60020%2C1519732668326.default.1522768773233. Name node is in safe mode.
</span></span><span class="line"><span class="cl">Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use &#34;hdfs dfsadmin -safemode leave&#34; to turn safe mode off.
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1418)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2674)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2561)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:593)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.create(AuthorizationProviderProxyClientProtocol.java:111)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:393)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
</span></span><span class="line"><span class="cl">    at java.security.AccessController.doPrivileged(Native Method)
</span></span><span class="line"><span class="cl">    at javax.security.auth.Subject.doAs(Subject.java:422)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Client.call(Client.java:1471)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.Client.call(Client.java:1408)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
</span></span><span class="line"><span class="cl">    at com.sun.proxy.$Proxy16.create(Unknown Source)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
</span></span><span class="line"><span class="cl">    at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
</span></span><span class="line"><span class="cl">    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span></span><span class="line"><span class="cl">    at java.lang.reflect.Method.invoke(Method.java:498)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
</span></span><span class="line"><span class="cl">    at com.sun.proxy.$Proxy17.create(Unknown Source)
</span></span><span class="line"><span class="cl">    at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
</span></span><span class="line"><span class="cl">    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span></span><span class="line"><span class="cl">    at java.lang.reflect.Method.invoke(Method.java:498)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
</span></span><span class="line"><span class="cl">    at com.sun.proxy.$Proxy18.create(Unknown Source)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1897)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1738)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1698)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:450)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:446)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive(DistributedFileSystem.java:446)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1124)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1100)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.init(ProtobufLogWriter.java:90)
</span></span><span class="line"><span class="cl">    at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:361)
</span></span><span class="line"><span class="cl">    ... 4 more
</span></span></code></pre></td></tr></table>
</div>
</div><p>可以看到上面的日志出现IO 出现异常，无法获取 <code>log writer</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">2018-04-03 23:19:33,472 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.LogRoller: Aborting
</span></span><span class="line"><span class="cl">java.io.IOException: cannot get log writer
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">2018-04-03 23:19:33,501 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.HRegionServer: ABORTING region server node2,60020,1519732668326: IOE in log roller
</span></span><span class="line"><span class="cl">java.io.IOException: cannot get log writer
</span></span></code></pre></td></tr></table>
</div>
</div><p>而无法获取 <code>log writer</code>, 对日志进行写入的原因是：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/hbase-nemo/WALs/node2,60020,1519732668326/node2%2C60020%2C1519732668326.default.1522768773233. Name node is in safe mode.
</span></span><span class="line"><span class="cl">Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use &#34;hdfs dfsadmin -safemode leave&#34; to turn safe mode off.
</span></span></code></pre></td></tr></table>
</div>
</div><p>NameNode 进入了safe-mode, 关于safe-mode 的描述：
&gt;During start up the NameNode loads the file system state from the fsimage and the edits log file. It then waits for DataNodes to report their blocks so that it does not prematurely start replicating the blocks though enough replicas already exist in the cluster. During this time NameNode stays in Safemode. Safemode for the NameNode is essentially a read-only mode for the HDFS cluster, where it does not allow any modifications to file system or blocks. Normally the NameNode leaves Safemode automatically after the DataNodes have reported that most file system blocks are available. If required, HDFS could be placed in Safemode explicitly using bin/hadoop dfsadmin -safemode command. NameNode front page shows whether Safemode is on or off. A more detailed description and configuration is maintained as JavaDoc for setSafeMode().</p>
<p>NameNode 进入safe-mode 的原因是因为 <code>node-master</code>这台Master 机器的磁盘被应用日志打满了，导 致 NameNode 进入了只读的 <code>safe-mode</code>. 因为NameNode 进入readonly 的safe-mode 就无 法写入日志, 所以 Hbase 在出现异常之后，就开始把Hbase 的信息 dump 出来，并关闭
Region Server, 导致整个Hbase 集群宕机。</p>
<p>对于<code>node2</code> Region Server 下线的原因，猜测是 NameNode 服务器的磁盘用完，导致NameNode 进入read-only 的safe-mode, 又因为Hbase 存储的核心之一是WAL(write-ahead-log, 预写日志),较长时间无法写入日志，最终导致 Region Server 下线。</p>
<h2 id="分析小结"><span class="section-num">3</span> 分析小结</h2>
<p>经过这样的一翻排查，可以得出结论，最开始 <code>node1</code> 因为Hbase 和 ZooKeeper 的通信出现问题， 被认为是问题节点，下线了Region Server；</p>
<p>一个星期之后，<code>node-master</code>这台机器在同步的时候 出现问题，想要关闭WAL, 但是却因为没有充足的健康节点来替换出现问题的<code>node1</code>, 导致关闭 WAL 失败，也下线了Region Server. <code>node2</code> 这台机器因为作为 NameNode 的<code>node-master</code>服务器的磁盘用 完，导致NameNode 进入read-only 的safe-mode, 又因为Hbase 存储的核心之一是
WAL(write-ahead-log, 预写日志),较长时间无法写入日志，最终导致 Region Server 下线。</p>
<h2 id="其他"><span class="section-num">4</span> 其他</h2>
<p>还有一个关键点是为什么Hbase 和Zookeeper 的连接超时，Zookeeper 的日志只是简单地说明：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">2018-03-13 14:47:46,926 [myid:1] - INFO  [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x161d6c1ae910002 for client /192.168.2.2:51611, probably expired
</span></span><span class="line"><span class="cl">2018-03-13 14:47:49,612 [myid:1] - INFO  [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x161d6c1ae910001 for client /192.168.2.2:51612, probably expired
</span></span></code></pre></td></tr></table>
</div>
</div><p>为什么 session 会无效，日志并没有给出说明，个人猜测可能是因为在部署了 Hbase/Zookeeper 的服务器上还部署了应用。</p>
<p>应用或者是Hbase 导致的长GC 导致ZooKeeper 停顿，并且导致session 超时无效。</p>
<h2 id="结语"><span class="section-num">5</span> 结语</h2>
<p>和同事交流之后，觉得以上的分析只是基于日志的猜测，可能Hbase 宕机的原因正如我所说， 或者另有原因，所以现在最关键的措施是加上对Hbase 的各种监控。</p>
<p>在Hbase 宕机的时候， 参考日志和详细的监控，比如连接数，CPU 使用率，内存，集群负载情况，每个节点情况。不然再遇到一次宕机，还是只能看日志，猜原因。</p>
<p>话分两头，现在的分析主要是基于Hbase 和ZooKeeper 的日志进行分析，简而言之就是捞日 志，查看信息; 捞日志，查看信息；通过工具找出日志中隐藏的关键时机，然后对时机前后发生的事情进行分析，这也是一个有趣的过程。</p>
<p>只是从1G 多的日志里面找出想要的内容，也不是一个容易的过程。</p>
<div center class="qr-container">
<img src="/ox-hugo/qrcode_gh_e06d750e626f_1.jpg" alt="qrcode_gh_e06d750e626f_1.jpg" width="160px" height="160px" center="t" class="qr-container" />
公号同步更新，欢迎关注👻
</div>
]]></content:encoded>
    </item>
    <item>
      <title>记存储集群的一次迁移过程（下）</title>
      <link>https://ramsayleung.github.io/zh/post/2018/store_cluster_migrate2/</link>
      <pubDate>Fri, 09 Mar 2018 13:55:00 +0800</pubDate>
      <guid>https://ramsayleung.github.io/zh/post/2018/store_cluster_migrate2/</guid>
      <description>&lt;p&gt;从Mysql, Hbase 迁移数据&lt;/p&gt;
&lt;h2 id=&#34;mysql-数据迁移&#34;&gt;&lt;span class=&#34;section-num&#34;&gt;1&lt;/span&gt; Mysql 数据迁移&lt;/h2&gt;
&lt;p&gt;搭建完之后就是数据迁移了，mysql 的数据迁移比较简单。在旧的机器用 mysqldump 把所 有的数据导出来，然后传到新的环境然后导出：&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>从Mysql, Hbase 迁移数据</p>
<h2 id="mysql-数据迁移"><span class="section-num">1</span> Mysql 数据迁移</h2>
<p>搭建完之后就是数据迁移了，mysql 的数据迁移比较简单。在旧的机器用 mysqldump 把所 有的数据导出来，然后传到新的环境然后导出：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">旧环境导出: mysqldump -u root -p --all-databases &gt; all_dbs.sql
</span></span><span class="line"><span class="cl">新环境导入: mysql -u root -p &lt; all_dbs.sql
</span></span></code></pre></td></tr></table>
</div>
</div><p>Mysql 集群在数据迁移的时候是在提供服务的，所以自然会有新数据写入，但因为是测试环 境，所以在迁移过程中可以忽略新数据写入的影响。不然这又会是一个大问题~</p>
<h2 id="hbase-数据迁移"><span class="section-num">2</span> Hbase 数据迁移</h2>
<h3 id="hbase-集群复制--cluster-replication"><span class="section-num">2.1</span> Hbase 集群复制(cluster replication)</h3>
<h4 id="配置旧集群和新集群"><span class="section-num">2.1.1</span> 配置旧集群和新集群</h4>
<p>在新的集群，创建和旧集群一样的表结构(table schema)和列族(column family),这样新的集群就知道在接收到旧集群数据时候怎么去保存。下面是具体的步骤：</p>
<ol>
<li>通过以下命令启动 Hbase Shell:</li>
</ol>
<!--listend-->
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">hbase shell
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li>通过下面的命令获取已有的表的元数据：</li>
</ol>
<!--listend-->
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">hbase&gt; describe <span class="s2">&#34;content&#34;</span><span class="p">;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>输入结果如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">Table content is ENABLED
</span></span><span class="line"><span class="cl">content, <span class="o">{</span><span class="nv">TABLE_ATTRIBUTES</span> <span class="o">=</span>&gt; <span class="o">{</span>coprocessor<span class="nv">$1</span> <span class="o">=</span>&gt; <span class="s1">&#39;|org.apache.phoenix.coprocessor.ScanRegionObserver|805306366|&#39;</span>, co
</span></span><span class="line"><span class="cl">processor<span class="nv">$2</span> <span class="o">=</span>&gt; <span class="s1">&#39;|org.apache.phoenix.coprocessor.UngroupedAggregateRegionObserver|805306366|&#39;</span>, coprocessor<span class="nv">$3</span> <span class="o">=</span>&gt; <span class="s1">&#39;|or
</span></span></span><span class="line"><span class="cl"><span class="s1">g.apache.phoenix.coprocessor.GroupedAggregateRegionObserver|805306366|&#39;</span>, coprocessor<span class="nv">$4</span> <span class="o">=</span>&gt; <span class="s1">&#39;|org.apache.phoenix.copr
</span></span></span><span class="line"><span class="cl"><span class="s1">ocessor.ServerCachingEndpointImpl|805306366|&#39;</span><span class="o">}</span>
</span></span><span class="line"><span class="cl">COLUMN FAMILIES DESCRIPTION
</span></span><span class="line"><span class="cl"><span class="o">{</span><span class="nv">NAME</span> <span class="o">=</span>&gt; <span class="s1">&#39;baseinfo&#39;</span>, <span class="nv">DATA_BLOCK_ENCODING</span> <span class="o">=</span>&gt; <span class="s1">&#39;NONE&#39;</span>, <span class="nv">BLOOMFILTER</span> <span class="o">=</span>&gt; <span class="s1">&#39;ROW&#39;</span>, <span class="nv">REPLICATION_SCOPE</span> <span class="o">=</span>&gt; <span class="s1">&#39;0&#39;</span>, <span class="nv">COMPRESSION</span> <span class="o">=</span>&gt;
</span></span><span class="line"><span class="cl"><span class="s1">&#39;NONE&#39;</span>, <span class="nv">VERSIONS</span> <span class="o">=</span>&gt; <span class="s1">&#39;1&#39;</span>, <span class="nv">MIN_VERSIONS</span> <span class="o">=</span>&gt; <span class="s1">&#39;0&#39;</span>, <span class="nv">TTL</span> <span class="o">=</span>&gt; <span class="s1">&#39;FOREVER&#39;</span>, <span class="nv">KEEP_DELETED_CELLS</span> <span class="o">=</span>&gt; <span class="s1">&#39;FALSE&#39;</span>, <span class="nv">BLOCKSIZE</span> <span class="o">=</span>&gt; <span class="s1">&#39;65536&#39;</span>
</span></span><span class="line"><span class="cl">, <span class="nv">IN_MEMORY</span> <span class="o">=</span>&gt; <span class="s1">&#39;false&#39;</span>, <span class="nv">BLOCKCACHE</span> <span class="o">=</span>&gt; <span class="s1">&#39;true&#39;</span><span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">{</span><span class="nv">NAME</span> <span class="o">=</span>&gt; <span class="s1">&#39;extrainfo&#39;</span>, <span class="nv">DATA_BLOCK_ENCODING</span> <span class="o">=</span>&gt; <span class="s1">&#39;NONE&#39;</span>, <span class="nv">BLOOMFILTER</span> <span class="o">=</span>&gt; <span class="s1">&#39;ROW&#39;</span>, <span class="nv">REPLICATION_SCOPE</span> <span class="o">=</span>&gt; <span class="s1">&#39;0&#39;</span>, <span class="nv">COMPRESSION</span> <span class="o">=</span>&gt;
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;NONE&#39;</span>, <span class="nv">VERSIONS</span> <span class="o">=</span>&gt; <span class="s1">&#39;1&#39;</span>, <span class="nv">MIN_VERSIONS</span> <span class="o">=</span>&gt; <span class="s1">&#39;0&#39;</span>, <span class="nv">TTL</span> <span class="o">=</span>&gt; <span class="s1">&#39;FOREVER&#39;</span>, <span class="nv">KEEP_DELETED_CELLS</span> <span class="o">=</span>&gt; <span class="s1">&#39;FALSE&#39;</span>, <span class="nv">BLOCKSIZE</span> <span class="o">=</span>&gt; <span class="s1">&#39;65536
</span></span></span><span class="line"><span class="cl"><span class="s1">&#39;</span>, <span class="nv">IN_MEMORY</span> <span class="o">=</span>&gt; <span class="s1">&#39;false&#39;</span>, <span class="nv">BLOCKCACHE</span> <span class="o">=</span>&gt; <span class="s1">&#39;true&#39;</span><span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="m">2</span> row<span class="o">(</span>s<span class="o">)</span> in 0.3060 seconds
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li>复制以下内容到编辑器，并按要求进行修改：</li>
</ol>
<!--listend-->
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="o">{</span><span class="nv">NAME</span> <span class="o">=</span>&gt; <span class="s1">&#39;baseinfo&#39;</span>, <span class="nv">DATA_BLOCK_ENCODING</span> <span class="o">=</span>&gt; <span class="s1">&#39;NONE&#39;</span>, <span class="nv">BLOOMFILTER</span> <span class="o">=</span>&gt; <span class="s1">&#39;ROW&#39;</span>, <span class="nv">REPLICATION_SCOPE</span> <span class="o">=</span>&gt; <span class="s1">&#39;0&#39;</span>, <span class="nv">COMPRESSION</span> <span class="o">=</span>&gt;
</span></span><span class="line"><span class="cl"><span class="s1">&#39;NONE&#39;</span>, <span class="nv">VERSIONS</span> <span class="o">=</span>&gt; <span class="s1">&#39;1&#39;</span>, <span class="nv">MIN_VERSIONS</span> <span class="o">=</span>&gt; <span class="s1">&#39;0&#39;</span>, <span class="nv">TTL</span> <span class="o">=</span>&gt; <span class="s1">&#39;FOREVER&#39;</span>, <span class="nv">KEEP_DELETED_CELLS</span> <span class="o">=</span>&gt; <span class="s1">&#39;FALSE&#39;</span>, <span class="nv">BLOCKSIZE</span> <span class="o">=</span>&gt; <span class="s1">&#39;65536&#39;</span>
</span></span><span class="line"><span class="cl">, <span class="nv">IN_MEMORY</span> <span class="o">=</span>&gt; <span class="s1">&#39;false&#39;</span>, <span class="nv">BLOCKCACHE</span> <span class="o">=</span>&gt; <span class="s1">&#39;true&#39;</span><span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">{</span><span class="nv">NAME</span> <span class="o">=</span>&gt; <span class="s1">&#39;extrainfo&#39;</span>, <span class="nv">DATA_BLOCK_ENCODING</span> <span class="o">=</span>&gt; <span class="s1">&#39;NONE&#39;</span>, <span class="nv">BLOOMFILTER</span> <span class="o">=</span>&gt; <span class="s1">&#39;ROW&#39;</span>, <span class="nv">REPLICATION_SCOPE</span> <span class="o">=</span>&gt; <span class="s1">&#39;0&#39;</span>, <span class="nv">COMPRESSION</span> <span class="o">=</span>&gt;
</span></span><span class="line"><span class="cl"> <span class="s1">&#39;NONE&#39;</span>, <span class="nv">VERSIONS</span> <span class="o">=</span>&gt; <span class="s1">&#39;1&#39;</span>, <span class="nv">MIN_VERSIONS</span> <span class="o">=</span>&gt; <span class="s1">&#39;0&#39;</span>, <span class="nv">TTL</span> <span class="o">=</span>&gt; <span class="s1">&#39;FOREVER&#39;</span>, <span class="nv">KEEP_DELETED_CELLS</span> <span class="o">=</span>&gt; <span class="s1">&#39;FALSE&#39;</span>, <span class="nv">BLOCKSIZE</span> <span class="o">=</span>&gt; <span class="s1">&#39;65536
</span></span></span><span class="line"><span class="cl"><span class="s1">&#39;</span>, <span class="nv">IN_MEMORY</span> <span class="o">=</span>&gt; <span class="s1">&#39;false&#39;</span>, <span class="nv">BLOCKCACHE</span> <span class="o">=</span>&gt; <span class="s1">&#39;true&#39;</span><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>将<code>TTL =&gt; 'FOREVER' with TTL</code> 修改成 <code>org.apache.hadoop.hbase.HConstants::FOREVER</code></p>
</li>
<li>
<p>在列族的描述之间加上逗号<code>,</code>用来在新建的时候分隔列族</p>
</li>
<li>
<p>去掉文本中的换汉符(<code>\n, \r</code>), 这样文本就会变成单行文本</p>
</li>
<li>
<p>通过下面的语句在新的集群创建新的相同的表：</p>
</li>
</ul>
<h4 id="copytable"><span class="section-num">2.1.2</span> CopyTable</h4>
<p>按照Apache 官方<a href="https://hbase.apache.org/book.html#ops.backup">文档</a>的介绍，Hbase 支持两种形式的数据备份，分别是停服和不停服的。</p>
<p>我选择的是不停服的形式，停服的代价太大。而不停服的数据备份有三种方案，我选择是的 <a href="https://hbase.apache.org/book.html#copy.table">CopyTable</a>方案。</p>
<!--list-separator-->
<ol>
<li>
<p>Add Peer</p>
<p>因为 <code>CopyTable</code> 需要源机房和目标机房是网络连通，并且是目标集群在源集群的 <code>peer</code> list里面。所以要先在源集群添加 <code>peer</code>. 按照 Hbase <a href="https://hbase.apache.org/book.html#_cluster_replication">cluster replication</a> 关于添加 <code>peer</code> 的说明：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">add_peer &lt;ID&gt; &lt;CLUSTER_KEY&gt;    Adds a replication relationship between two clusters.
</span></span><span class="line"><span class="cl">       + ID — a unique string, which must not contain a hyphen.
</span></span><span class="line"><span class="cl">       + CLUSTER_KEY: composed using the following template, with appropriate
</span></span><span class="line"><span class="cl">	 place-holders:
</span></span><span class="line"><span class="cl">	 <span class="sb">`</span>hbase.zookeeper.quorum:hbase.zookeeper.property.clientPort:zookeeper.znode.parent<span class="sb">`</span>
</span></span><span class="line"><span class="cl">       + STATE<span class="o">(</span>optional<span class="o">)</span>: ENABLED or DISABLED, default value is ENABLED
</span></span></code></pre></td></tr></table>
</div>
</div><p>而 <code>hbase.zookeeper.quorum</code> 可以在目标集群的 <code>$HBASE_HOME/conf/hbase-site.xml</code>
目录找到设置的值； <code>hbase.zookeeper.property.clientPort</code> 可以在 <code>$HBASE_HOME/conf/hbase-site.xml</code>指定或者是在 <code>$ZOOKEEPER_HOME/conf/zoo.cfg</code>通 过 <code>clientPort</code> 指定； <code>zookeeper.znode.parent</code> 默认值是 <code>/hbase</code></p>
<p>所以，在 Hbase Shell 运行下面的命令来添加 <code>peer</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">add_peer <span class="s1">&#39;1&#39;</span>, <span class="s2">&#34;node-master,node1,node2:2181:/hbase&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<h4 id="复制表和数据"><span class="section-num">2.1.3</span> 复制表和数据</h4>
<p><code>CopyTable</code> 的命令说明如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">./bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable --help
</span></span><span class="line"><span class="cl">/bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable --help
</span></span><span class="line"><span class="cl">Usage: CopyTable <span class="o">[</span>general options<span class="o">]</span> <span class="o">[</span>--starttime<span class="o">=</span>X<span class="o">]</span> <span class="o">[</span>--endtime<span class="o">=</span>Y<span class="o">]</span> <span class="o">[</span>--new.name<span class="o">=</span>NEW<span class="o">]</span> <span class="o">[</span>--peer.adr<span class="o">=</span>ADR<span class="o">]</span> &lt;tablename&gt;
</span></span></code></pre></td></tr></table>
</div>
</div><p>可以指定需要复制的数据的时间间隔，也可以不指定。那么默认是全部数据，以 <code>cset_content</code> 表为例，复制一个小时的数据：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">bin/hbase org.apache.hadoop.hbase.mapreduce.CopyTable --starttime<span class="o">=</span><span class="m">1265875194289</span> --endtime<span class="o">=</span><span class="m">1265878794289</span>  --peer.adr<span class="o">=</span>node-master,node1,node2:2181:/hbase --families<span class="o">=</span>baseinfo,extrainfo cset_content
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后Hadoop 就会启动一个 MapReduce 的Job来运行这个 <code>CopyTable</code>任务。而我要复制所 有的数据，就需要把列族和表都列出来</p>
<h2 id="结语"><span class="section-num">3</span> 结语</h2>
<p>折腾一波之后，终于把环境弄好。如果目标机房和源机房不同的话，也可以尝试使用 Hbase 的 <code>Exporter</code> 和 <code>Importer</code></p>
<div center class="qr-container">
<img src="/ox-hugo/qrcode_gh_e06d750e626f_1.jpg" alt="qrcode_gh_e06d750e626f_1.jpg" width="160px" height="160px" center="t" class="qr-container" />
公号同步更新，欢迎关注👻
</div>
]]></content:encoded>
    </item>
    <item>
      <title>记存储集群的一次迁移过程（上）</title>
      <link>https://ramsayleung.github.io/zh/post/2018/store_cluster_migrate1/</link>
      <pubDate>Mon, 05 Mar 2018 17:39:00 +0800</pubDate>
      <guid>https://ramsayleung.github.io/zh/post/2018/store_cluster_migrate1/</guid>
      <description>&lt;p&gt;搭建和配置 Hadoop, Zookeeper, Hbase&lt;/p&gt;
&lt;h2 id=&#34;前言&#34;&gt;&lt;span class=&#34;section-num&#34;&gt;1&lt;/span&gt; 前言&lt;/h2&gt;
&lt;p&gt;最近负责公司测试环境的迁移，主要包括 Hbase+Mysql 存储集群的迁移，消息队列，缓存组件的迁移, 而我打算说说存储集群的迁移。因为公司的机器的Ip 和Host 不便在博文展示，所以我会用：&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>搭建和配置 Hadoop, Zookeeper, Hbase</p>
<h2 id="前言"><span class="section-num">1</span> 前言</h2>
<p>最近负责公司测试环境的迁移，主要包括 Hbase+Mysql 存储集群的迁移，消息队列，缓存组件的迁移, 而我打算说说存储集群的迁移。因为公司的机器的Ip 和Host 不便在博文展示，所以我会用：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cfg" data-lang="cfg"><span class="line"><span class="cl"><span class="na">192.168.2.1: node-master</span>
</span></span><span class="line"><span class="cl"><span class="na">192.168.2.2: node1</span>
</span></span><span class="line"><span class="cl"><span class="na">192.168.2.3: node2</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>来代替公司的机器和域名。</p>
<h2 id="搭建新环境"><span class="section-num">2</span> 搭建新环境</h2>
<h3 id="hadoop-搭建流程"><span class="section-num">2.1</span> Hadoop 搭建流程</h3>
<h4 id="hadoop-集群的架构"><span class="section-num">2.1.1</span> Hadoop 集群的架构</h4>
<p>在配置 Hadoop 的主从节点(master/slave)之前，先来了解一下 Hadoop 集群的组件作用；</p>
<ul>
<li><code>master</code> 节点负责担任管理分布式文件系统以及进行相应的资源调度的角色:
<ul>
<li>NameNode: 管理分布式文件系统并且感知数据块在集群的存储位置</li>
<li>ResourceManager: 管理 <code>YARN</code> 任务，并且负责在 <code>slave</code> 节点调度和处理</li>
</ul>
</li>
<li><code>slave</code> 节点负责担任存储真实的数据并且提供运算 <code>YARN</code> 任务的能力的角色：
<ul>
<li>DataNode: 负责物理存储真实的数据</li>
<li>NodeManager: 管理在该节点 <code>YARN</code> 任务的具体执行。</li>
</ul>
</li>
</ul>
<p><code>master</code> 和 <code>slave</code> 的角色不一定像上面划分得泾渭分明，比如 <code>master</code> 节点也可以是 <code>dataNode</code>,这个就看具体配置了。</p>
<h4 id="配置jdk"><span class="section-num">2.1.2</span> 配置JDK</h4>
<p>Hadoop 集群需要JAVA 环境，而Linux 的发行版本一般都是默认带有JDK 的，只是OpenJDK 而不是 Oracle JDK, 如果需要修改JDK 的版本，可以自行修改，网上已经有很多安装JDK 的教程，我就不一一讲解了。</p>
<h4 id="修改host"><span class="section-num">2.1.3</span> 修改host</h4>
<p>因为需要不同的机器之间通信，所以需要先配置好Ip 和域名的映射。修改每台机器的 <code>/etc/hosts</code> 文件，加上以下内容：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">192.168.2.1: nodw-master
</span></span><span class="line"><span class="cl">192.168.2.2: node1
</span></span><span class="line"><span class="cl">192.168.2.3: node2
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="新建-hadoop-用户"><span class="section-num">2.1.4</span> 新建 hadoop 用户</h4>
<p>虽说我可以用我自己的登录名来配置和运行 hadoop, 但是出于安全的考虑，还是在每个节点创建一个专门用来运行 hadoop 集群的用户比较好。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">useradd hadoop
</span></span><span class="line"><span class="cl">passwd hadoop
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="ssh-免密码登录"><span class="section-num">2.1.5</span> SSH 免密码登录</h4>
<p>因为在 Hadoop 集群中， <code>node-master</code> 节点会通过SSH连接和其他节点进行通信，所以需要为
Hadoop 集群配置免密码校验的通信。首先以 <code>hadoop</code> 用户身份登录到 <code>node-master</code> 节点，然后生成 SSH的公私钥：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">ssh-keygen -b <span class="m">4096</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后把公钥复制到其他的节点，如果你想要把 <code>node-master</code>也当作<code>dataNote</code>的话，就需要把公钥也复制到
<code>master</code>节点：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">ssh-copy-id -i $HOME/.ssh/id_rsa.pub hadoop@node-master
</span></span><span class="line"><span class="cl">ssh-copy-id -i $HOME/.ssh/id_rsa.pub hadoop@node1
</span></span><span class="line"><span class="cl">ssh-copy-id -i $HOME/.ssh/id_rsa.pub hadoop@node2
</span></span></code></pre></td></tr></table>
</div>
</div><p>谨记：复制的是”公钥”,不是”私钥”.</p>
<h4 id="安装hadoop-1-dot-下载hadoop-安装包-以-hadoop-登录-node-master-采用-wget命令下载"><span class="section-num">2.1.6</span> 安装hadoop 1. 下载hadoop 安装包，以 <code>hadoop</code>登录<code>node-master</code>，采用 wget命令下载：</h4>
<p>wget <a href="http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.1.tar.gz">http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.7.1.tar.gz</a></p>
<ol>
<li>创建一个hadoop目录，将各个组件都安装在这个目录。</li>
</ol>
<!--listend-->
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">mdkir ~/hadoop
</span></span><span class="line"><span class="cl">tar -zxvf hadoop-2.6.0-cdh5.7.1.tar.gz -C ~/hadoop
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="修改配置文件"><span class="section-num">2.1.7</span> 修改配置文件</h4>
<p>所有修改的 hadoop配置文件都位于 ~/hadoop/etc/hadoop/ 目录</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">cd ~/hadoop/etc/hadoop
</span></span></code></pre></td></tr></table>
</div>
</div><!--list-separator-->
<ol>
<li>
<p>设置 NameNode 位置</p>
<p><code>vim core-site.xml</code>: 修改成以下内容：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-xml" data-lang="xml"><span class="line"><span class="cl"><span class="nt">&lt;configuration&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>hdfs://node-master:19000<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>fs.trash.interval<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>10080<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>fs.trash.checkpoint.interval<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>10080<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/configuration&gt;</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="2">
<li>
<p>设置 HDFS 路径</p>
<p><code>vim hdfs-site.xml</code>,修改内容为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-xml" data-lang="xml"><span class="line"><span class="cl"><span class="nt">&lt;configuration&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>/home/hadoop/hadoop/data/temp<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.namenode.http-address<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>node-master:50070<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.namenode.secondary.http-address<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>node1:50090<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.webhdfs.enabled<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>dfs.data.dir<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>/home/hadoop/hadoop/data/hdfs<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/configuration&gt;</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="3">
<li>
<p>将 YARN 设置成任务调度器(Job Scheduler)</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">cp mapred-site.xml.template mapred-site.xml
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后修改配置，将 <code>yarn</code> 设置成 <code>MapReduce</code> 操作的默认框架：
<code>vim mapred-site.xml</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-xml" data-lang="xml"><span class="line"><span class="cl"><span class="nt">&lt;configuration&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>mapreduce.jobhistory.address<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>node-master:10020<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>mapreduce.jobhistory.webapp.address<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>node-master:19888<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/configuration&gt;</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="4">
<li>
<p>配置 YARN</p>
<p><code>vim yarn-site.xml</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-xml" data-lang="xml"><span class="line"><span class="cl"><span class="nt">&lt;configuration&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.acl.enable<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>0<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>node-master<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/configuration&gt;</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="5">
<li>
<p>配置 master 节点</p>
<p>因为公司的机器内存较大，兼之机器数不多，所以我就把两台机器都都当作 <code>master</code>:
<code>vim masters</code>修改文件为：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cfg" data-lang="cfg"><span class="line"><span class="cl"><span class="na">node-master</span>
</span></span><span class="line"><span class="cl"><span class="na">node1</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="6">
<li>
<p>配置 slave 节点</p>
<p>把全部节点都当作数据几点(dataNode):
<code>vim slaves</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cfg" data-lang="cfg"><span class="line"><span class="cl"><span class="na">node-master</span>
</span></span><span class="line"><span class="cl"><span class="na">node1</span>
</span></span><span class="line"><span class="cl"><span class="na">node2</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="7">
<li>
<p>修改 Hadoop 环境变量配置</p>
<p>这个配置是否修改就视情况而定了。
<code>vim hadoop-env.sh</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1">#因为ssh的端口不是默认的22,需要重新指定</span>
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">HADOOP_SSH_OPTS</span><span class="o">=</span><span class="s2">&#34;-p 9922&#34;</span>
</span></span><span class="line"><span class="cl"><span class="c1">#如果报错java_home找不到，可在这里重新指定</span>
</span></span><span class="line"><span class="cl"><span class="c1">#export JAVA_HOME=/usr/java/jdk1.8.0_161/</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="8">
<li>在其它的节点安装并且解压，不要修改配置文件</li>
</ol>
<!--list-separator-->
<ol start="9">
<li>
<p>将配置文件同步到slave主机</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">scp -r -P <span class="m">9922</span> /home/hadoop/hadoop/hadoop-2.6.0-cdh5.7.1/etc/hadoop/  node1:/home/hadoop/hadoop/hadoop-2.6.0-cdh5.7.1/etc
</span></span><span class="line"><span class="cl">scp -r -P <span class="m">9922</span> /home/hadoop/hadoop/hadoop-2.6.0-cdh5.7.1/etc/hadoop/  node2:/home/hadoop/hadoop/hadoop-2.6.0-cdh5.7.1/etc
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="10">
<li>修改环境变量（所有节点都要配置）</li>
</ol>
<pre><code>编辑 `.bash_profile`：
`vim ~/.bash_profile`
加入：

```shell
export JAVA_HOME=/usr/java/jdk1.8.0_161/
export JRE_HOME=/usr/java/jdk1.8.0_161/jre
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH
export HADOOP_HOME=/home/hadoop/hadoop/hadoop-2.6.0-cdh5.7.1
export HBASE_HOME=/home/hadoop/hadoop/hbase-1.2.0-cdh5.7.1
export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export YARN_HOME=${HADOOP_HOME}
export HADOOP_YARN_HOME=${HADOOP_HOME}
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HDFS_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export YARN_CONF_DIR=${HADOOP_HOME}/etc/hadoop
PATH=$PATH:$HOME/bin:$JAVA_HOME/bin:$HADOOP_HOME/sbin:$HBASE_HOME/bin:$HADOOP_HOME/bin
export PATH
```

然后加载 `~/.bash_profile`:
`source ~/.bash_profile`
</code></pre>
<!--list-separator-->
<ol start="11">
<li>格式化 HDFS</li>
</ol>
<pre><code>就像其它的文件系统那样，在使用之前需要格式化，HDFS 这个分布式文件系统也不例外。在 `node-master`,运行：

```nil
hdfs namenode -format
```

那么，到目前为止， Hadoop 就已经安装和配置好了。
</code></pre>
<h4 id="运行和监控-hdfs"><span class="section-num">2.1.8</span> 运行和监控 HDFS</h4>
<!--list-separator-->
<ol>
<li>
<p>启动HDFS</p>
<p>在 <code>node-master</code> 的 <code>/home/hadoop/hadoop/sbin/</code> 目录运行下面的命令以启动 HDFS:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">./start-dfs.sh
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后就会启动 <code>NameNode</code> 和 <code>SecondaryNameNode</code>, 然后继续启动 <code>DataNode</code>.</p>
</li>
</ol>
<!--list-separator-->
<ol start="2">
<li>
<p>验证HDFS</p>
<p>可以在各个节点通过 <code>jps</code> 检查HDFS 的运行状态。比如在 <code>node-master</code> 运行 <code>jps</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cfg" data-lang="cfg"><span class="line"><span class="cl"><span class="na">12243 NameNode</span>
</span></span><span class="line"><span class="cl"><span class="na">2677 ResourceManager</span>
</span></span><span class="line"><span class="cl"><span class="na">19593 Jps</span>
</span></span><span class="line"><span class="cl"><span class="na">15036 DataNode</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>node1</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cfg" data-lang="cfg"><span class="line"><span class="cl"><span class="na">30464 DataNode</span>
</span></span><span class="line"><span class="cl"><span class="na">13094 Jps</span>
</span></span><span class="line"><span class="cl"><span class="na">28589 SecondaryNameNode</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="3">
<li>
<p>停止HDFS</p>
<p>在 <code>node-master</code> 的 <code>/home/hadoop/hadoop/sbin/</code> 目录运行下面的命令以停止HDFS:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">./stop-dfs.sh
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<!--list-separator-->
<ol start="4">
<li>
<p>监控HDFS</p>
<p>如果你在启动 HDFS 之后，想要获取关于 HDFS 的详细信息，你可以使用 <code>hdfs dfsadmin -report</code> 命令， 例如在 <code>node-master</code> 运行 <code>hdfs dfsadmin -resport</code>, 输出如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cfg" data-lang="cfg"><span class="line"><span class="cl"><span class="na">Configured Capacity: 1201169780736 (1.09 TB)</span>
</span></span><span class="line"><span class="cl"><span class="na">Present Capacity: 1129442681745 (1.03 TB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Remaining: 1129442358161 (1.03 TB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Used: 323584 (316 KB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Used%: 0.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">Under replicated blocks: 0</span>
</span></span><span class="line"><span class="cl"><span class="na">Blocks with corrupt replicas: 0</span>
</span></span><span class="line"><span class="cl"><span class="na">Missing blocks: 0</span>
</span></span><span class="line"><span class="cl"><span class="na">Missing blocks (with replication factor 1): 0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="na">-------------------------------------------------</span>
</span></span><span class="line"><span class="cl"><span class="na">Live datanodes (3):</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="na">Name: 192.168.2.3:50010 (node2)</span>
</span></span><span class="line"><span class="cl"><span class="na">Hostname: node2</span>
</span></span><span class="line"><span class="cl"><span class="na">Decommission Status : Normal</span>
</span></span><span class="line"><span class="cl"><span class="na">Configured Capacity: 400389926912 (372.89 GB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Used: 102400 (100 KB)</span>
</span></span><span class="line"><span class="cl"><span class="na">Non DFS Used: 24759164513 (23.06 GB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Remaining: 375630659999 (349.83 GB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Used%: 0.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Remaining%: 93.82%</span>
</span></span><span class="line"><span class="cl"><span class="na">Configured Cache Capacity: 0 (0 B)</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Used: 0 (0 B)</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Remaining: 0 (0 B)</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Used%: 100.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Remaining%: 0.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">Xceivers: 11</span>
</span></span><span class="line"><span class="cl"><span class="na">Last contact: Mon Mar 05 14:05:38 CST 2018</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="na">Name: 192.168.2.2:50010 (node1)</span>
</span></span><span class="line"><span class="cl"><span class="na">Hostname: node1</span>
</span></span><span class="line"><span class="cl"><span class="na">Decommission Status : Normal</span>
</span></span><span class="line"><span class="cl"><span class="na">Configured Capacity: 400389926912 (372.89 GB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Used: 77824 (76 KB)</span>
</span></span><span class="line"><span class="cl"><span class="na">Non DFS Used: 23483977479 (21.87 GB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Remaining: 376905871609 (351.02 GB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Used%: 0.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Remaining%: 94.13%</span>
</span></span><span class="line"><span class="cl"><span class="na">Configured Cache Capacity: 0 (0 B)</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Used: 0 (0 B)</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Remaining: 0 (0 B)</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Used%: 100.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Remaining%: 0.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">Xceivers: 7</span>
</span></span><span class="line"><span class="cl"><span class="na">Last contact: Mon Mar 05 14:05:38 CST 2018</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="na">Name: 192.168.2.1:50010 (node-master)</span>
</span></span><span class="line"><span class="cl"><span class="na">Hostname: node-master</span>
</span></span><span class="line"><span class="cl"><span class="na">Decommission Status : Normal</span>
</span></span><span class="line"><span class="cl"><span class="na">Configured Capacity: 400389926912 (372.89 GB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Used: 143360 (140 KB)</span>
</span></span><span class="line"><span class="cl"><span class="na">Non DFS Used: 23483956999 (21.87 GB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Remaining: 376905826553 (351.02 GB)</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Used%: 0.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">DFS Remaining%: 94.13%</span>
</span></span><span class="line"><span class="cl"><span class="na">Configured Cache Capacity: 0 (0 B)</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Used: 0 (0 B)</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Remaining: 0 (0 B)</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Used%: 100.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">Cache Remaining%: 0.00%</span>
</span></span><span class="line"><span class="cl"><span class="na">Xceivers: 7</span>
</span></span><span class="line"><span class="cl"><span class="na">Last contact: Mon Mar 05 14:05:39 CST 2018</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>或者可以使用更加友好的 Web 管理界面，在浏览器输入： <a href="http://node-master-ip:50070">http://node-master-ip:50070</a>, 然后你就可以看到如下的监控界面：
<img loading="lazy" src="https://imgur.com/jmIXxRy.jpg"></p>
</li>
</ol>
<!--list-separator-->
<ol start="5">
<li>
<p>使用 HDFS</p>
<p>既然 HDFS 可以跑起来了，现在就需要添加一点数据以测试 HDFS 了。 在HDFS 的根目录下新建一个 <code>test</code> 目录：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">hdfs dfs -mkdir /test
</span></span></code></pre></td></tr></table>
</div>
</div><p>然后在本地创建一个 <code>helloworld</code> 文件，内容如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">Bye world!
</span></span></code></pre></td></tr></table>
</div>
</div><p>接着把 <code>helloworld</code> 文件放置到HDFS的 <code>/test</code> 目录下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">hdfs dfs -put helloworld /test
</span></span></code></pre></td></tr></table>
</div>
</div><p>最后查看文件是否存在：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">hdfs dfs -ls /test
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<h3 id="小结"><span class="section-num">2.2</span> 小结</h3>
<p>至此，如果一切顺利的话， 那么Hadoop 集群就运行起来了。因为我是需要用Hbase 作存储集群，暂不需用<code>Yarn</code> 作计算，所以我就没有介绍启动 <code>Yarn</code> 的 流程了。</p>
<h3 id="zookeeper-搭建流程"><span class="section-num">2.3</span> ZooKeeper 搭建流程</h3>
<p>因为需要用 ZooKeeper 来管理集群，所以也需要安装 ZooKeeper. 而 ZooKeeper 的安装和 配置也是用 <code>hadoop</code> 用户进行操作的。</p>
<h4 id="安装zookeeper--每个节点同样的操作--1-dot-下载zookeeper安装包-登录主机-采用wget命令下载"><span class="section-num">2.3.1</span> 安装zookeeper (每个节点同样的操作) 1. 下载zookeeper安装包，登录主机，采用wget命令下载：</h4>
<p>wget <a href="http://archive.cloudera.com/cdh5/cdh/5/zookeeper-3.4.5-cdh5.7.1.tar.gz">http://archive.cloudera.com/cdh5/cdh/5/zookeeper-3.4.5-cdh5.7.1.tar.gz</a></p>
<ol>
<li>解压安装到hadoop目录，将各个组件都安装在这个目录。</li>
</ol>
<!--listend-->
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">tar -zxvf zookeeper-3.4.5-cdh5.7.1.tar.gz -C ~/hadoop
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="配置-zookeeper"><span class="section-num">2.3.2</span> 配置 ZooKeeper</h4>
<p>修改zoo.cfg (所有机器一样的配置): <code>vim /home/hadoop/hadoop/zookeeper-3.4.5-cdh5.7.1/conf/zoo.cfg</code>, 配置文件内容如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cfg" data-lang="cfg"><span class="line"><span class="cl"><span class="c1"># The number of milliseconds of each tick</span>
</span></span><span class="line"><span class="cl"><span class="na">tickTime</span><span class="o">=</span><span class="s">2000</span>
</span></span><span class="line"><span class="cl"><span class="na">maxSessionTimeout</span><span class="o">=</span><span class="s">300000</span>
</span></span><span class="line"><span class="cl"><span class="c1"># The number of ticks that the initial</span>
</span></span><span class="line"><span class="cl"><span class="c1"># synchronization phase can take</span>
</span></span><span class="line"><span class="cl"><span class="na">initLimit</span><span class="o">=</span><span class="s">10</span>
</span></span><span class="line"><span class="cl"><span class="c1"># The number of ticks that can pass between</span>
</span></span><span class="line"><span class="cl"><span class="c1"># sending a request and getting an acknowledgement</span>
</span></span><span class="line"><span class="cl"><span class="na">syncLimit</span><span class="o">=</span><span class="s">5</span>
</span></span><span class="line"><span class="cl"><span class="c1"># the directory where the snapshot is stored.</span>
</span></span><span class="line"><span class="cl"><span class="c1"># do not use /tmp for storage, /tmp here is just</span>
</span></span><span class="line"><span class="cl"><span class="c1"># example sakes.</span>
</span></span><span class="line"><span class="cl"><span class="na">dataDir</span><span class="o">=</span><span class="s">/home/hadoop/hadoop/zookeeper-3.4.5-cdh5.7.1/data</span>
</span></span><span class="line"><span class="cl"><span class="c1"># the port at which the clients will connect</span>
</span></span><span class="line"><span class="cl"><span class="na">clientPort</span><span class="o">=</span><span class="s">2181</span>
</span></span><span class="line"><span class="cl"><span class="c1">#</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Be sure to read the maintenance section of the</span>
</span></span><span class="line"><span class="cl"><span class="c1"># administrator guide before turning on autopurge.</span>
</span></span><span class="line"><span class="cl"><span class="c1">#</span>
</span></span><span class="line"><span class="cl"><span class="c1"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span>
</span></span><span class="line"><span class="cl"><span class="c1">#</span>
</span></span><span class="line"><span class="cl"><span class="c1"># The number of snapshots to retain in dataDir</span>
</span></span><span class="line"><span class="cl"><span class="c1">#autopurge.snapRetainCount=3</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Purge task interval in hours</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Set to &#34;0&#34; to disable auto purge feature</span>
</span></span><span class="line"><span class="cl"><span class="c1">#autopurge.purgeInterval=1</span>
</span></span><span class="line"><span class="cl"><span class="na">server.1</span><span class="o">=</span><span class="s">node-master:2888:3888</span>
</span></span><span class="line"><span class="cl"><span class="na">server.2</span><span class="o">=</span><span class="s">node1:2888:3888</span>
</span></span><span class="line"><span class="cl"><span class="na">server.3</span><span class="o">=</span><span class="s">node2:2888:3888</span>
</span></span></code></pre></td></tr></table>
</div>
</div><!--list-separator-->
<ol>
<li>
<p>创建myid文件 （不同主机不同数字）</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="nb">cd</span> <span class="o">{</span>data_dir<span class="o">}</span> <span class="c1"># 按照上面的配置，就应该是/home/hadoop/hadoop/zookeeper-3.4.5-cdh5.7.1/data</span>
</span></span><span class="line"><span class="cl">vim myid
</span></span></code></pre></td></tr></table>
</div>
</div><p>myid的数字要与zoo.cfg配置的一一对应。即要对应：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-cfg" data-lang="cfg"><span class="line"><span class="cl"><span class="na">server.1</span><span class="o">=</span><span class="s">node-master:2888:3888</span>
</span></span><span class="line"><span class="cl"><span class="na">server.2</span><span class="o">=</span><span class="s">node1:2888:3888</span>
</span></span><span class="line"><span class="cl"><span class="na">server.3</span><span class="o">=</span><span class="s">node2:2888:3888</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>也就是 <code>node-master</code> 的 <code>myid</code>是<code>1</code>, <code>node1</code>的 <code>myid</code>是 <code>2</code>,依次类推。需要注意的 是，数字前后都不能有空格！</p>
</li>
</ol>
<!--list-separator-->
<ol start="2">
<li>
<p>启动 ZooKeeper</p>
<p>在 <code>node-master</code> 的 <code>/home/hadoop/hadoop/zookeeper-3.4.5-cdh5.7.1</code> 目录，运行以 下命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">sh bin/zkServer.sh start
</span></span></code></pre></td></tr></table>
</div>
</div><p>其它相应的命令如下：</p>
<ul>
<li>启动ZK服务: <code>sh bin/zkServer.sh start</code></li>
<li>查看ZK服务状态: <code>sh bin/zkServer.sh status</code></li>
<li>停止ZK服务: <code>sh bin/zkServer.sh stop</code></li>
<li>重启ZK服务: <code>sh bin/zkServer.sh restart</code></li>
</ul>
</li>
</ol>
<!--list-separator-->
<ol start="3">
<li>
<p>验证 ZooKeeper</p>
<p>可以通过调用 <code>jps</code> 或者 <code>bin/zkCli.sh</code> 来验证 Zookeeper 的运行情况：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">./zkCli.sh -server 192.168.2.1:2181
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<h3 id="hbase-搭建流程"><span class="section-num">2.4</span> HBase 搭建流程</h3>
<h4 id="安装hbase"><span class="section-num">2.4.1</span> 安装Hbase</h4>
<ol>
<li>下载hbase 安装包，登录主机，采用wget命令下载：
wget <a href="http://archive.cloudera.com/cdh5/cdh/5/hbase-1.2.0-cdh5.7.1.tar.gz">http://archive.cloudera.com/cdh5/cdh/5/hbase-1.2.0-cdh5.7.1.tar.gz</a>
2、解压安装到hadoop目录（3台主机同样操作）</li>
</ol>
<!--listend-->
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">tar -zxvf hbase-1.2.0-cdh5.7.1.tar.gz -C ~/hadoop
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="修改hbase的配置文件--所有主机一样的配置"><span class="section-num">2.4.2</span> 修改hbase的配置文件(所有主机一样的配置)</h4>
<p>修改 <code>hbase-1.2.0-cdh5.7.1/conf</code> 目录下的文件： 1. 修改 <code>hbase-site.xml</code> 内容如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-xml" data-lang="xml"><span class="line"><span class="cl"><span class="nt">&lt;configuration&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>hbase.rootdir<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>hdfs://node-master:19000/hbase-${user.name}<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>hbase.master<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>node-master<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>hbase.cluster.distributed<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>hbase.tmp.dir<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>/home/hadoop/hadoop/data/hbase-${user.name}<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;property&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;name&gt;</span>hbase.zookeeper.quorum<span class="nt">&lt;/name&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="nt">&lt;value&gt;</span>node-master, node1, node2<span class="nt">&lt;/value&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;/property&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/configuration&gt;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li>修改 <code>hbase-env.sh</code>:</li>
</ol>
<!--listend-->
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/java/jdk1.8.0_161/ <span class="o">(</span>无法识别系统的环境变量，在这里直接指定<span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">HBASE_MANAGES_ZK</span><span class="o">=</span><span class="nb">false</span>  （关闭自带的zookeeper）
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">HBASE_SSH_OPTS</span><span class="o">=</span><span class="s2">&#34;-p 9922&#34;</span> <span class="o">(</span>端口号不是默认的22，要改为9922<span class="o">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol>
<li>修改 =regionservers=(指定regionservers的主机地址):</li>
</ol>
<!--listend-->
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">node-master
</span></span><span class="line"><span class="cl">node1
</span></span><span class="line"><span class="cl">node2
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="启动-hbase"><span class="section-num">2.4.3</span> 启动 Hbase</h4>
<p>在 <code>node-master</code> 的 <code>/home/hadoop/hadoop/hbase-1.2.0-cdh5.7.1/bin</code> 目录下运行：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">start-hbase.sh
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="监控-hbase"><span class="section-num">2.4.4</span> 监控 Hbase</h4>
<p>可以在浏览器查看 HBase 集群的信息：</p>
<ul>
<li>HMaster web 管理信息：<a href="http://192.168.2.1:60010/master-status">http://192.168.2.1:60010/master-status</a></li>
<li>HregionServer 管理信息：<a href="http://192.168.2.1:60030/">http://192.168.2.1:60030/</a> <a href="http://192.168.2.2:60030/">http://192.168.2.2:60030/</a></li>
</ul>
<p><a href="http://192.168.2.3:60030/">http://192.168.2.3:60030/</a></p>
<h2 id="结语"><span class="section-num">3</span> 结语</h2>
<p>整个 Hbase 集群应该搭建完了，关于Mysql 搭建的文章就太多了，我也不赘言了。至此，所有存储的组件就已经安装完毕并已启用，但是都是没有数据的，接下来我们需要做的是如何将旧的测试环境的数据迁移到新的测试环境。考虑到这篇内容已经很长了，剩下的内容我就另外写一篇博文了。</p>
<h2 id="参考"><span class="section-num">4</span> 参考</h2>
<ul>
<li><a href="http://blog.csdn.net/u010824591/article/details/51174099">http://blog.csdn.net/u010824591/article/details/51174099</a></li>
<li><a href="https://yq.aliyun.com/articles/26415">https://yq.aliyun.com/articles/26415</a></li>
<li><a href="https://linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/">https://linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/</a></li>
</ul>
<div center class="qr-container">
<img src="/ox-hugo/qrcode_gh_e06d750e626f_1.jpg" alt="qrcode_gh_e06d750e626f_1.jpg" width="160px" height="160px" center="t" class="qr-container" />
公号同步更新，欢迎关注👻
</div>
]]></content:encoded>
    </item>
  </channel>
</rss>
