<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>记一次Hbase 宕机原因分析 | 过河卒</title>
<meta name=keywords content="hbase"><meta name=description content="1 背景 在2018年4月4号早上，业务方反应Hbase 读超时，无法读取当前数据。然后发现测试环境的 Hbase region server 全部宕机，已经无可用Region Server. 因为"><meta name=author content="Ramsay Leung"><link rel=canonical href=https://ramsayleung.github.io/zh/post/2018/hbase_crash/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.b5612927541b0be426261b01846ad2324c2a9f0a7d2b22c2c58252ae5352bc17.css integrity="sha256-tWEpJ1QbC+QmJhsBhGrSMkwqnwp9KyLCxYJSrlNSvBc=" rel="preload stylesheet" as=style><link rel=icon href=https://ramsayleung.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://ramsayleung.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://ramsayleung.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://ramsayleung.github.io/apple-touch-icon.png><link rel=mask-icon href=https://ramsayleung.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://ramsayleung.github.io/zh/post/2018/hbase_crash/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-9MG65HQHEL"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-9MG65HQHEL",{anonymize_ip:!1})}</script><meta property="og:title" content="记一次Hbase 宕机原因分析"><meta property="og:description" content="1 背景 在2018年4月4号早上，业务方反应Hbase 读超时，无法读取当前数据。然后发现测试环境的 Hbase region server 全部宕机，已经无可用Region Server. 因为"><meta property="og:type" content="article"><meta property="og:url" content="https://ramsayleung.github.io/zh/post/2018/hbase_crash/"><meta property="og:image" content="https://ramsayleung.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post"><meta property="article:published_time" content="2018-04-04T19:54:00+08:00"><meta property="article:modified_time" content="2022-02-24T22:58:14+08:00"><meta property="og:site_name" content="Ramsay's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://ramsayleung.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="记一次Hbase 宕机原因分析"><meta name=twitter:description content="1 背景 在2018年4月4号早上，业务方反应Hbase 读超时，无法读取当前数据。然后发现测试环境的 Hbase region server 全部宕机，已经无可用Region Server. 因为"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ramsayleung.github.io/zh/post/"},{"@type":"ListItem","position":2,"name":"记一次Hbase 宕机原因分析","item":"https://ramsayleung.github.io/zh/post/2018/hbase_crash/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"记一次Hbase 宕机原因分析","name":"记一次Hbase 宕机原因分析","description":"1 背景 在2018年4月4号早上，业务方反应Hbase 读超时，无法读取当前数据。然后发现测试环境的 Hbase region server 全部宕机，已经无可用Region Server. 因为","keywords":["hbase"],"articleBody":"1 背景 在2018年4月4号早上，业务方反应Hbase 读超时，无法读取当前数据。然后发现测试环境的 Hbase region server 全部宕机，已经无可用Region Server. 因为公司的机器的Ip 和Host 不便在博文展示，所以我会用：\n1 2 3 192.168.2.1: node-master 192.168.2.2: node1 192.168.2.3: node2 来代替\n2 Region Server 宕机原因分析 经查看日志，发现三台部署了Hbase 的服务器，分别是node-master 192.168.2.1, node1 192.168.2.2,=node2 192.168.2.3=. node1 机器在2018-03-13 14:47:55 收到了Shutdown Message, 停了Region Server. node-master这台机器在2018-03-20 10:13:07收到了Shutdown Message, 停掉了Region Server.\n也就是说在3月下旬到昨天，Hbase 一直只有一台Region Server 在运行。而在昨天，2018-04-03 23:19:35, 剩下的最后一台机器也收到了Shutdown Message, 因此把剩下的最后一台Region Server 停掉，测试 环境的Hbase 全部下线。那么，为什么这三台服务器会收到Shutdown Message 呢？\n2.1 node1 先从 node1这台机器开始分析，关于 Region Server 退出的日志显示如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 2018-03-13 14:47:49,665 INFO [main-SendThread(node-master:2181)] zookeeper.ClientCnxn: Unable to reconnect to ZooKeeper service, session 0x161d6c1ae910001 has expired, closing socket connection 2018-03-13 14:47:49,706 FATAL [main-EventThread] regionserver.HRegionServer: ABORTING region server node1,60020,1519732610839: regionserver:60020-0x161d6c1ae910001, quorum=node-master:2181,node1:2181,node2:2181, baseZNode=/hbase regionserver:60020-0x161d6c1ae910001 received expired from ZooKeeper, aborting org.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.connectionEvent(ZooKeeperWatcher.java:700) at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.process(ZooKeeperWatcher.java:611) at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522) at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) 2018-03-13 14:47:49,718 FATAL [main-EventThread] regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: [org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint] 2018-03-13 14:47:50,705 WARN [DataStreamer for file /hbase-nemo/WALs/node1,60020,1519732610839/node1%2C60020%2C1519732610839.default.1520922158622 block BP-1296874721-192.168.2.1-1519712987003:blk_1073743994_3170] hdfs.DFSClient: DataStreamer Exception org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): No lease on /hbase-nemo/oldWALs/node1%2C60020%2C1519732610839.default.1520922158622 (inode 18837): File is not open for writing. [Lease. Holder: DFSClient_NONMAPREDUCE_551822027_1, pendingcreates: 1] at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3612) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalDatanode(FSNamesystem.java:3516) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getAdditionalDatanode(NameNodeRpcServer.java:711) at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getAdditionalDatanode(AuthorizationProviderProxyClientProtocol.java:229) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getAdditionalDatanode(ClientNamenodeProtocolServerSideTranslatorPB.java:508) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080) at org.apache.hadoop.ipc.Client.call(Client.java:1471) at org.apache.hadoop.ipc.Client.call(Client.java:1408) at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230) at com.sun.proxy.$Proxy16.getAdditionalDatanode(Unknown Source) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getAdditionalDatanode(ClientNamenodeProtocolTranslatorPB.java:429) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256) at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104) at com.sun.proxy.$Proxy17.getAdditionalDatanode(Unknown Source) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279) at com.sun.proxy.$Proxy18.getAdditionalDatanode(Unknown Source) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1228) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1119) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:622) 2018-03-13 14:47:53,803 FATAL [regionserver/node1/192.168.2.2:60020] regionserver.HRegionServer: ABORTING region server node1,60020,1519732610839: org.apache.hadoop.hbase.YouAreDeadException: Server REPORT rejected; currently processing node1,60020,1519732610839 as dead server 从 14:47:49 开始， Hbase 没法和 Zookeeper 通信，连接时间超时。翻查 Zookeeper 的日志，发现Zookeeper 的日志有如下内容：\n1 2 3 4 2018-03-13 14:47:46,926 [myid:1] - INFO [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x161d6c1ae910002 for client /192.168.2.2:51611, probably expired 2018-03-13 14:47:49,612 [myid:1] - INFO [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x161d6c1ae910001 for client /192.168.2.2:51612, probably expired 说明Hbase 和 ZooKeeper 的通信的确去了问题。连接出问题以后，集群就会认为 这个 Hbase 的节点出了故障，宕机，然后就把这个节点当作 DeadNode, 这个节点的 RegionServer 就下线了。\n2.2 node-master 现在再来看看node-master这台机器的日志\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 2018-03-20 10:12:19,986 INFO [main-SendThread(node-master:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x361d65049260001, likely server has closed socket, closing socket connection and attempting reconnect 2018-03-20 10:12:20,841 INFO [main-SendThread(node1:2181)] zookeeper.ClientCnxn: Opening socket connection to server node1/192.168.2.2:2181. Will not attempt to authenticate using SASL (unknown error) 2018-03-20 10:12:43,747 INFO [regionserver/node-master/192.168.2.1:60020-SendThread(node1:2181)] zookeeper.ClientCnxn: Client session timed out, have not heard from server in 60019ms for sessionid 0x161d65049590000, closing socket connection and attempting reconnect 2018-03-20 10:12:44,574 INFO [regionserver/node-master/192.168.2.1:60020-SendThread(node-master:2181)] zookeeper.ClientCnxn: Opening socket connection to server node-master/192.168.2.1:2181. Will not attempt to authenticate using SASL (unknown error) 2018-03-20 10:12:44,575 INFO [regionserver/node-master/192.168.2.1:60020-SendThread(node-master:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.2.1:58042, server: node-master/192.168.2.1:2181 2018-03-20 10:12:44,577 INFO [regionserver/node-master/192.168.2.1:60020-SendThread(node-master:2181)] zookeeper.ClientCnxn: Session establishment complete on server node-master/192.168.2.1:2181, sessionid = 0x161d65049590000, negotiated timeout = 90000 2018-03-20 10:12:49,625 INFO [main-SendThread(node1:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.2.1:46815, server: node1/192.168.2.2:2181 2018-03-20 10:12:53,258 WARN [ResponseProcessor for block BP-1296874721-192.168.2.1-1519712987003: blk_1073747108_6286] hdfs.DFSClient: Slow ReadProcessor read fields took 70070ms (threshold=30000ms); ack: seqno: -2 reply: 0 reply: 1 downstreamAckTimeNanos: 0, targets: [DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.2:50010,DS-4eb97418-f0a1-45a7-b335-83f77e4d6a7b,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]] 2018-03-20 10:12:53,259 WARN [ResponseProcessor for block BP-1296874721-192.168.2.1-1519712987003:blk_1073747108_6286] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception for block BP-1296874721-192.168.2.1-1519712987003:blk_1073747108_6286 java.io.IOException: Bad response ERROR for block BP-1296874721-192.168.2.1-1519712987003:blk_1073747108_6286 from datanode DatanodeInfoWithStorage[192.168.2.2:50010,DS-4eb97418-f0a1-45a7-b335-83f77e4d6a7b,DISK] at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:1002) 2018-03-20 10:12:53,259 WARN [DataStreamer for file /hbase-nemo/WALs/node-master,60020,1519720160721/node-master%2C60020%2C1519720160721.default.1521509628323 block BP-1296874721-192.168.2.1-1519712987003:blk_1073747108_6286] hdfs.DFSClient: Error Recovery for block BP-1296874721-192.168.2.1-1519712987003:blk_1073747108_6286 in pipeline DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.2:50010,DS-4eb97418-f0a1-45a7-b335-83f77e4d6a7b,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]: bad datanode DatanodeInfoWithStorage[192.168.2.2:50010,DS-4eb97418-f0a1-45a7-b335-83f77e4d6a7b,DISK] 2018-03-20 10:12:53,264 WARN [DataStreamer for file /hbase-nemo/WALs/node-master,60020,1519720160721/node-master%2C60020%2C1519720160721.default.1521509628323 block BP-1296874721-192.168.2.1-1519712987003:blk_1073747108_6286] hdfs.DFSClient: DataStreamer Exception java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration. at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1119) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:622) 2018-03-20 10:12:53,265 WARN [sync.4] hdfs.DFSClient: Error while syncing java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration. at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1119) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:622) 2018-03-20 10:12:53,266 ERROR [sync.4] wal.FSHLog: Error syncing, request close of WAL java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration. at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1119) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:622) 2018-03-20 10:12:53,266 INFO [sync.4] wal.FSHLog: Slow sync cost: 474 ms, current pipeline: [DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]] 2018-03-20 10:13:05,816 INFO [regionserver/node-master/192.168.2.1:60020.logRoller] wal.FSHLog: Slow sync cost: 12546 ms, current pipeline: [DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]] 2018-03-20 10:13:05,817 ERROR [sync.0] wal.FSHLog: Error syncing, request close of WAL java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration. at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1119) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:622) 2018-03-20 10:13:05,817 ERROR [regionserver/node-master/192.168.2.1:60020.logRoller] wal.FSHLog: Failed close of WAL writer hdfs://node-master:19000/hbase-nemo/WALs/node-master,60020,1519720160721/node-master%2C60020%2C1519720160721.default.1521509628323, unflushedEntries=1 org.apache.hadoop.hbase.regionserver.wal.FailedSyncBeforeLogCloseException: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration. at org.apache.hadoop.hbase.regionserver.wal.FSHLog$SafePointZigZagLatch.waitSafePoint(FSHLog.java:1615) at org.apache.hadoop.hbase.regionserver.wal.FSHLog.replaceWriter(FSHLog.java:833) at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:699) at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148) at java.lang.Thread.run(Thread.java:748) Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration. at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1119) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:622) 2018-03-20 10:13:05,818 FATAL [regionserver/node-master/192.168.2.1:60020.logRoller] regionserver.HRegionServer: ABORTING region server node-master,60020,1519720160721: Failed log close in log roller org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException: hdfs://node-master:19000/hbase-nemo/WALs/node-master,60020,1519720160721/node-master%2C60020%2C1519720160721.default.1521509628323, unflushedEntries=1 at org.apache.hadoop.hbase.regionserver.wal.FSHLog.replaceWriter(FSHLog.java:882) at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:699) at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.hadoop.hbase.regionserver.wal.FailedSyncBeforeLogCloseException: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration. at org.apache.hadoop.hbase.regionserver.wal.FSHLog$SafePointZigZagLatch.waitSafePoint(FSHLog.java:1615) at org.apache.hadoop.hbase.regionserver.wal.FSHLog.replaceWriter(FSHLog.java:833) ... 3 more Caused by: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration. at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode(DFSOutputStream.java:1162) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:1236) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1404) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:1119) at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:622) 2018-03-20 10:13:05,818 FATAL [regionserver/node-master/192.168.2.1:60020.logRoller] regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: [] 2018-03-20 10:13:05,997 INFO [regionserver/node-master/192.168.2.1:60020.logRoller] regionserver.HRegionServer: Dump of metrics as JSON on abort: 从上面的日志可以看到 node-master与node1机器通信，获取node1 的响应失败，认为node1 是 bad DataNode，接着集群想要把出现问题的DataNode 下掉，却发现没有多余DataNode 来替换， 紧接着在Syncing 时出错，关闭 WAL 失败, 最后就停掉了Region Server. 比较关键的时机如下：\n1 2 3 4 5 6 7 2018-03-20 10:12:53,265 WARN [sync.4] hdfs.DFSClient: Error while syncing 2018-03-20 10:12:53,266 ERROR [sync.4] wal.FSHLog: Error syncing, request close of WAL 2018-03-20 10:13:05,817 ERROR [sync.0] wal.FSHLog: Error syncing, request close of WAL 2018-03-20 10:13:06,397 ERROR [regionserver/node-master/192.168.2.1:60020] regionserver.HRegionServer: Shutdown / close of WAL failed: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration. 期间HDFS 同步出错，尝试关闭WAL, 失败。失败的原因是无法用健康的节点替换出了问题的节点， 应该是健康的节点数太少了。最后在多次尝试关闭WAL都因为IOException 失败之后， RegionServer 下线。只是为什么尝试关闭WAL 失败需要关闭Region Server 依然存疑。\n2.3 node2 node2 是Hbase 集群最后一台机器，当node2 倒下了，Hbase 就真的完全宕机了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 2018-04-03 23:19:33,472 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.LogRoller: Aborting java.io.IOException: cannot get log writer at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:365) at org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:724) at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:689) at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/hbase-nemo/WALs/node2,60020,1519732668326/node2%2C60020%2C1519732668326.default.1522768773233. Name node is in safe mode. Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE: If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use \"hdfs dfsadmin -safemode leave\" to turn safe mode off. at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1418) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2674) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2561) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:593) at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.create(AuthorizationProviderProxyClientProtocol.java:111) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:393) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080) at org.apache.hadoop.ipc.Client.call(Client.java:1471) at org.apache.hadoop.ipc.Client.call(Client.java:1408) at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230) at com.sun.proxy.$Proxy16.create(Unknown Source) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296) at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256) at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104) at com.sun.proxy.$Proxy17.create(Unknown Source) at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279) at com.sun.proxy.$Proxy18.create(Unknown Source) at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1897) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1738) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1698) at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:450) at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:446) at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) at org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive(DistributedFileSystem.java:446) at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1124) at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1100) at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.init(ProtobufLogWriter.java:90) at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:361) ... 4 more 2018-04-03 23:19:33,501 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.HRegionServer: ABORTING region server node2,60020,1519732668326: IOE in log roller java.io.IOException: cannot get log writer at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:365) at org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:724) at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:689) at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148) at java.lang.Thread.run(Thread.java:748) Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/hbase-nemo/WALs/node2,60020,1519732668326/node2%2C60020%2C1519732668326.default.1522768773233. Name node is in safe mode. Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE: If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use \"hdfs dfsadmin -safemode leave\" to turn safe mode off. at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1418) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2674) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2561) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:593) at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.create(AuthorizationProviderProxyClientProtocol.java:111) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:393) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080) at org.apache.hadoop.ipc.Client.call(Client.java:1471) at org.apache.hadoop.ipc.Client.call(Client.java:1408) at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230) at com.sun.proxy.$Proxy16.create(Unknown Source) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296) at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256) at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104) at com.sun.proxy.$Proxy17.create(Unknown Source) at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279) at com.sun.proxy.$Proxy18.create(Unknown Source) at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1897) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1738) at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1698) at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:450) at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:446) at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) at org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive(DistributedFileSystem.java:446) at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1124) at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1100) at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.init(ProtobufLogWriter.java:90) at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:361) ... 4 more 可以看到上面的日志出现IO 出现异常，无法获取 log writer:\n1 2 3 4 5 2018-04-03 23:19:33,472 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.LogRoller: Aborting java.io.IOException: cannot get log writer 2018-04-03 23:19:33,501 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.HRegionServer: ABORTING region server node2,60020,1519732668326: IOE in log roller java.io.IOException: cannot get log writer 而无法获取 log writer, 对日志进行写入的原因是：\n1 2 Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/hbase-nemo/WALs/node2,60020,1519732668326/node2%2C60020%2C1519732668326.default.1522768773233. Name node is in safe mode. Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE: If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use \"hdfs dfsadmin -safemode leave\" to turn safe mode off. NameNode 进入了safe-mode, 关于safe-mode 的描述： \u003eDuring start up the NameNode loads the file system state from the fsimage and the edits log file. It then waits for DataNodes to report their blocks so that it does not prematurely start replicating the blocks though enough replicas already exist in the cluster. During this time NameNode stays in Safemode. Safemode for the NameNode is essentially a read-only mode for the HDFS cluster, where it does not allow any modifications to file system or blocks. Normally the NameNode leaves Safemode automatically after the DataNodes have reported that most file system blocks are available. If required, HDFS could be placed in Safemode explicitly using bin/hadoop dfsadmin -safemode command. NameNode front page shows whether Safemode is on or off. A more detailed description and configuration is maintained as JavaDoc for setSafeMode().\nNameNode 进入safe-mode 的原因是因为 node-master这台Master 机器的磁盘被应用日志打满了，导 致 NameNode 进入了只读的 safe-mode. 因为NameNode 进入readonly 的safe-mode 就无 法写入日志, 所以 Hbase 在出现异常之后，就开始把Hbase 的信息 dump 出来，并关闭 Region Server, 导致整个Hbase 集群宕机。\n对于node2 Region Server 下线的原因，猜测是 NameNode 服务器的磁盘用完，导致NameNode 进入read-only 的safe-mode, 又因为Hbase 存储的核心之一是WAL(write-ahead-log, 预写日志),较长时间无法写入日志，最终导致 Region Server 下线。\n3 分析小结 经过这样的一翻排查，可以得出结论，最开始 node1 因为Hbase 和 ZooKeeper 的通信出现问题， 被认为是问题节点，下线了Region Server；\n一个星期之后，node-master这台机器在同步的时候 出现问题，想要关闭WAL, 但是却因为没有充足的健康节点来替换出现问题的node1, 导致关闭 WAL 失败，也下线了Region Server. node2 这台机器因为作为 NameNode 的node-master服务器的磁盘用 完，导致NameNode 进入read-only 的safe-mode, 又因为Hbase 存储的核心之一是 WAL(write-ahead-log, 预写日志),较长时间无法写入日志，最终导致 Region Server 下线。\n4 其他 还有一个关键点是为什么Hbase 和Zookeeper 的连接超时，Zookeeper 的日志只是简单地说明：\n1 2 2018-03-13 14:47:46,926 [myid:1] - INFO [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x161d6c1ae910002 for client /192.168.2.2:51611, probably expired 2018-03-13 14:47:49,612 [myid:1] - INFO [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x161d6c1ae910001 for client /192.168.2.2:51612, probably expired 为什么 session 会无效，日志并没有给出说明，个人猜测可能是因为在部署了 Hbase/Zookeeper 的服务器上还部署了应用。\n应用或者是Hbase 导致的长GC 导致ZooKeeper 停顿，并且导致session 超时无效。\n5 结语 和同事交流之后，觉得以上的分析只是基于日志的猜测，可能Hbase 宕机的原因正如我所说， 或者另有原因，所以现在最关键的措施是加上对Hbase 的各种监控。\n在Hbase 宕机的时候， 参考日志和详细的监控，比如连接数，CPU 使用率，内存，集群负载情况，每个节点情况。不然再遇到一次宕机，还是只能看日志，猜原因。\n话分两头，现在的分析主要是基于Hbase 和ZooKeeper 的日志进行分析，简而言之就是捞日 志，查看信息; 捞日志，查看信息；通过工具找出日志中隐藏的关键时机，然后对时机前后发生的事情进行分析，这也是一个有趣的过程。\n只是从1G 多的日志里面找出想要的内容，也不是一个容易的过程。\n公号同步更新，欢迎关注👻 ","wordCount":"3883","inLanguage":"zh","image":"https://ramsayleung.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2018-04-04T19:54:00+08:00","dateModified":"2022-02-24T22:58:14+08:00","author":{"@type":"Person","name":"Ramsay Leung"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ramsayleung.github.io/zh/post/2018/hbase_crash/"},"publisher":{"@type":"Organization","name":"过河卒","logo":{"@type":"ImageObject","url":"https://ramsayleung.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://ramsayleung.github.io/zh/ accesskey=h title="Home (Alt + H)"><img src=https://ramsayleung.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://ramsayleung.github.io/en/ title=English aria-label=English>En</a></li></ul></div></div><ul id=menu><li class=dropdown><a href=https://ramsayleung.github.io/zh/categories/ title="系列 "><span>系列 ▾</span></a><div class="menu-more-content dropdown-content"><a href=https://ramsayleung.github.io/zh/categories/%E5%BE%97%E5%A4%B1%E6%84%9F%E6%82%9F/ title=得失感悟><span>得失感悟
</span></a><a href=https://ramsayleung.github.io/zh/categories/%E6%97%85%E5%8A%A0%E7%BB%8F%E5%8E%86 title=旅加经历><span>旅加经历
</span></a><a href=https://ramsayleung.github.io/zh/categories/%E5%B7%A5%E4%BD%9C%E6%B5%81/ title=我的工作流><span>我的工作流
</span></a><a href=https://ramsayleung.github.io/zh/categories/%E6%B5%8B%E8%AF%95%E6%8A%80%E8%83%BD%E8%BF%9B%E9%98%B6/ title=测试技能进阶><span>测试技能进阶
</span></a><a href=https://ramsayleung.github.io/zh/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E8%BD%AF%E6%8A%80%E8%83%BD%E6%8C%87%E5%8C%97/ title=软件工程师的软技能指北><span>软件工程师的软技能指北
</span></a><a href=https://ramsayleung.github.io/zh/categories/reinvent-%E9%87%8D%E6%96%B0%E9%80%A0%E8%BD%AE%E5%AD%90%E7%B3%BB%E5%88%97 title=Reinvent-重新造轮子系列><span>Reinvent-重新造轮子系列</span></a></div></li><li><a href=https://ramsayleung.github.io/zh/archives/ title=归档><span>归档</span></a></li><li><a href=https://ramsayleung.github.io/zh/search/ title=搜索><span>搜索</span></a></li><li><a href=https://ramsayleung.github.io/zh/tags/ title=标签><span>标签</span></a></li><li><a href=https://ramsayleung.github.io/zh/about_me_zh/ title=关于><span>关于</span></a></li><li><a href=https://ramsayleung.github.io/zh/index.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://ramsayleung.github.io/zh/>主页</a>&nbsp;»&nbsp;<a href=https://ramsayleung.github.io/zh/post/>Posts</a></div><h1 class="post-title entry-hint-parent">记一次Hbase 宕机原因分析</h1><div class=post-meta><span title='2018-04-04 19:54:00 +0800 +0800'>四月 4, 2018</span>&nbsp;·&nbsp;8 分钟&nbsp;·&nbsp;3883 字&nbsp;·&nbsp;Ramsay Leung&nbsp;|&nbsp;<a href=https://github.com/ramsayleung/ramsayleung.github.io/blob/master/content/post/2018/hbase_crash.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#背景><span class=section-num>1</span> 背景</a></li><li><a href=#region-server-宕机原因分析><span class=section-num>2</span> Region Server 宕机原因分析</a><ul><li><a href=#node1><span class=section-num>2.1</span> node1</a></li><li><a href=#node-master><span class=section-num>2.2</span> node-master</a></li><li><a href=#node2><span class=section-num>2.3</span> node2</a></li></ul></li><li><a href=#分析小结><span class=section-num>3</span> 分析小结</a></li><li><a href=#其他><span class=section-num>4</span> 其他</a></li><li><a href=#结语><span class=section-num>5</span> 结语</a></li></ul></nav></div></details></div><div class=post-content><h2 id=背景><span class=section-num>1</span> 背景<a hidden class=anchor aria-hidden=true href=#背景>#</a></h2><p>在2018年4月4号早上，业务方反应Hbase 读超时，无法读取当前数据。然后发现测试环境的
Hbase region server 全部宕机，已经无可用Region Server. 因为公司的机器的Ip 和Host
不便在博文展示，所以我会用：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>192.168.2.1: node-master
</span></span><span class=line><span class=cl>192.168.2.2: node1
</span></span><span class=line><span class=cl>192.168.2.3: node2
</span></span></code></pre></td></tr></table></div></div><p>来代替</p><h2 id=region-server-宕机原因分析><span class=section-num>2</span> Region Server 宕机原因分析<a hidden class=anchor aria-hidden=true href=#region-server-宕机原因分析>#</a></h2><p>经查看日志，发现三台部署了Hbase 的服务器，分别是<code>node-master 192.168.2.1</code>, <code>node1 192.168.2.2</code>,=node2 192.168.2.3=. node1 机器在2018-03-13 14:47:55 收到了Shutdown Message, 停了Region Server. node-master这台机器在2018-03-20
10:13:07收到了Shutdown Message, 停掉了Region Server.</p><p>也就是说在3月下旬到昨天，Hbase 一直只有一台Region Server 在运行。而在昨天，2018-04-03 23:19:35, 剩下的最后一台机器也收到了Shutdown Message, 因此把剩下的最后一台Region Server 停掉，测试 环境的Hbase 全部下线。那么，为什么这三台服务器会收到Shutdown Message 呢？</p><h3 id=node1><span class=section-num>2.1</span> node1<a hidden class=anchor aria-hidden=true href=#node1>#</a></h3><p>先从 node1这台机器开始分析，关于 Region Server 退出的日志显示如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>13</span> <span class=mi>14</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>49</span><span class=p>,</span><span class=mi>665</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>main</span><span class=o>-</span><span class=n>SendThread</span><span class=p>(</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>:</span><span class=mi>2181</span><span class=p>)]</span> <span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>Unable</span> <span class=n>to</span> <span class=n>reconnect</span> <span class=n>to</span> <span class=n>ZooKeeper</span> <span class=n>service</span><span class=p>,</span> <span class=n>session</span> <span class=mh>0x161d6c1ae910001</span> <span class=n>has</span> <span class=n>expired</span><span class=p>,</span> <span class=n>closing</span> <span class=n>socket</span> <span class=n>connection</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>13</span> <span class=mi>14</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>49</span><span class=p>,</span><span class=mi>706</span> <span class=n>FATAL</span> <span class=p>[</span><span class=n>main</span><span class=o>-</span><span class=n>EventThread</span><span class=p>]</span> <span class=n>regionserver</span><span class=o>.</span><span class=n>HRegionServer</span><span class=p>:</span> <span class=n>ABORTING</span> <span class=n>region</span> <span class=n>server</span> <span class=n>node1</span><span class=p>,</span><span class=mi>60020</span><span class=p>,</span><span class=mi>1519732610839</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>regionserver</span><span class=p>:</span><span class=mi>60020</span><span class=o>-</span><span class=mh>0x161d6c1ae910001</span><span class=p>,</span> <span class=n>quorum</span><span class=o>=</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>:</span><span class=mi>2181</span><span class=p>,</span><span class=n>node1</span><span class=p>:</span><span class=mi>2181</span><span class=p>,</span><span class=n>node2</span><span class=p>:</span><span class=mi>2181</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=n>baseZNode</span><span class=o>=/</span><span class=n>hbase</span> <span class=n>regionserver</span><span class=p>:</span><span class=mi>60020</span><span class=o>-</span><span class=mh>0x161d6c1ae910001</span> <span class=n>received</span> <span class=n>expired</span> <span class=n>from</span> <span class=n>ZooKeeper</span><span class=p>,</span> <span class=n>aborting</span>
</span></span><span class=line><span class=cl><span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>zookeeper</span><span class=o>.</span><span class=n>KeeperException</span><span class=o>$</span><span class=n>SessionExpiredException</span><span class=p>:</span> <span class=n>KeeperErrorCode</span> <span class=o>=</span> <span class=n>Session</span> <span class=n>expired</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>zookeeper</span><span class=o>.</span><span class=n>ZooKeeperWatcher</span><span class=o>.</span><span class=n>connectionEvent</span><span class=p>(</span><span class=n>ZooKeeperWatcher</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>700</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>zookeeper</span><span class=o>.</span><span class=n>ZooKeeperWatcher</span><span class=o>.</span><span class=n>process</span><span class=p>(</span><span class=n>ZooKeeperWatcher</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>611</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=o>$</span><span class=n>EventThread</span><span class=o>.</span><span class=n>processEvent</span><span class=p>(</span><span class=n>ClientCnxn</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>522</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=o>$</span><span class=n>EventThread</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>ClientCnxn</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>498</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>13</span> <span class=mi>14</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>49</span><span class=p>,</span><span class=mi>718</span> <span class=n>FATAL</span> <span class=p>[</span><span class=n>main</span><span class=o>-</span><span class=n>EventThread</span><span class=p>]</span> <span class=n>regionserver</span><span class=o>.</span><span class=n>HRegionServer</span><span class=p>:</span> <span class=n>RegionServer</span> <span class=n>abort</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>loaded</span> <span class=n>coprocessors</span> <span class=n>are</span><span class=p>:</span> <span class=p>[</span><span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>coprocessor</span><span class=o>.</span><span class=n>MultiRowMutationEndpoint</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>13</span> <span class=mi>14</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>50</span><span class=p>,</span><span class=mi>705</span> <span class=n>WARN</span>  <span class=p>[</span><span class=n>DataStreamer</span> <span class=k>for</span> <span class=n>file</span> <span class=o>/</span><span class=n>hbase</span><span class=o>-</span><span class=n>nemo</span><span class=o>/</span><span class=n>WALs</span><span class=o>/</span><span class=n>node1</span><span class=p>,</span><span class=mi>60020</span><span class=p>,</span><span class=mi>1519732610839</span><span class=o>/</span><span class=n>node1</span><span class=o>%</span><span class=mi>2</span><span class=n>C60020</span><span class=o>%</span><span class=mi>2</span><span class=n>C1519732610839</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=mi>1520922158622</span> <span class=n>block</span> <span class=n>BP</span><span class=o>-</span><span class=mi>1296874721</span><span class=o>-</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=o>-</span><span class=mi>1519712987003</span><span class=p>:</span><span class=n>blk_1073743994_3170</span><span class=p>]</span> <span class=n>hdfs</span><span class=o>.</span><span class=n>DFSClient</span><span class=p>:</span> <span class=n>DataStreamer</span> <span class=n>Exception</span>
</span></span><span class=line><span class=cl><span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>ipc</span><span class=o>.</span><span class=n>RemoteException</span><span class=p>(</span><span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>server</span><span class=o>.</span><span class=n>namenode</span><span class=o>.</span><span class=n>LeaseExpiredException</span><span class=p>):</span>
</span></span><span class=line><span class=cl><span class=n>No</span> <span class=n>lease</span> <span class=n>on</span> <span class=o>/</span><span class=n>hbase</span><span class=o>-</span><span class=n>nemo</span><span class=o>/</span><span class=n>oldWALs</span><span class=o>/</span><span class=n>node1</span><span class=o>%</span><span class=mi>2</span><span class=n>C60020</span><span class=o>%</span><span class=mi>2</span><span class=n>C1519732610839</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=mi>1520922158622</span> <span class=p>(</span><span class=n>inode</span> <span class=mi>18837</span><span class=p>):</span>
</span></span><span class=line><span class=cl><span class=ne>File</span> <span class=n>is</span> <span class=ow>not</span> <span class=n>open</span> <span class=k>for</span> <span class=n>writing</span><span class=o>.</span> <span class=p>[</span><span class=n>Lease</span><span class=o>.</span>  <span class=n>Holder</span><span class=p>:</span> <span class=n>DFSClient_NONMAPREDUCE_551822027_1</span><span class=p>,</span> <span class=n>pendingcreates</span><span class=p>:</span> <span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>server</span><span class=o>.</span><span class=n>namenode</span><span class=o>.</span><span class=n>FSNamesystem</span><span class=o>.</span><span class=n>checkLease</span><span class=p>(</span><span class=n>FSNamesystem</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>3612</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>server</span><span class=o>.</span><span class=n>namenode</span><span class=o>.</span><span class=n>FSNamesystem</span><span class=o>.</span><span class=n>getAdditionalDatanode</span><span class=p>(</span><span class=n>FSNamesystem</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>3516</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>server</span><span class=o>.</span><span class=n>namenode</span><span class=o>.</span><span class=n>NameNodeRpcServer</span><span class=o>.</span><span class=n>getAdditionalDatanode</span><span class=p>(</span><span class=n>NameNodeRpcServer</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>711</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>server</span><span class=o>.</span><span class=n>namenode</span><span class=o>.</span><span class=n>AuthorizationProviderProxyClientProtocol</span><span class=o>.</span><span class=n>getAdditionalDatanode</span><span class=p>(</span><span class=n>AuthorizationProviderProxyClientProtocol</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>229</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>protocolPB</span><span class=o>.</span><span class=n>ClientNamenodeProtocolServerSideTranslatorPB</span><span class=o>.</span><span class=n>getAdditionalDatanode</span><span class=p>(</span><span class=n>ClientNamenodeProtocolServerSideTranslatorPB</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>508</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>protocol</span><span class=o>.</span><span class=n>proto</span><span class=o>.</span><span class=n>ClientNamenodeProtocolProtos</span><span class=o>$</span><span class=n>ClientNamenodeProtocol</span><span class=o>$</span><span class=mf>2.</span><span class=n>callBlockingMethod</span><span class=p>(</span><span class=n>ClientNamenodeProtocolProtos</span><span class=o>.</span><span class=n>java</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>ipc</span><span class=o>.</span><span class=n>ProtobufRpcEngine</span><span class=o>$</span><span class=n>Server</span><span class=o>$</span><span class=n>ProtoBufRpcInvoker</span><span class=o>.</span><span class=n>call</span><span class=p>(</span><span class=n>ProtobufRpcEngine</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>617</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>ipc</span><span class=o>.</span><span class=n>RPC</span><span class=o>$</span><span class=n>Server</span><span class=o>.</span><span class=n>call</span><span class=p>(</span><span class=n>RPC</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1073</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>ipc</span><span class=o>.</span><span class=n>Server</span><span class=o>$</span><span class=n>Handler</span><span class=o>$</span><span class=mf>1.</span><span class=n>run</span><span class=p>(</span><span class=n>Server</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>2086</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>ipc</span><span class=o>.</span><span class=n>Server</span><span class=o>$</span><span class=n>Handler</span><span class=o>$</span><span class=mf>1.</span><span class=n>run</span><span class=p>(</span><span class=n>Server</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>2082</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>java</span><span class=o>.</span><span class=n>security</span><span class=o>.</span><span class=n>AccessController</span><span class=o>.</span><span class=n>doPrivileged</span><span class=p>(</span><span class=n>Native</span> <span class=n>Method</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>javax</span><span class=o>.</span><span class=n>security</span><span class=o>.</span><span class=n>auth</span><span class=o>.</span><span class=n>Subject</span><span class=o>.</span><span class=n>doAs</span><span class=p>(</span><span class=n>Subject</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>422</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>security</span><span class=o>.</span><span class=n>UserGroupInformation</span><span class=o>.</span><span class=n>doAs</span><span class=p>(</span><span class=n>UserGroupInformation</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1693</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>ipc</span><span class=o>.</span><span class=n>Server</span><span class=o>$</span><span class=n>Handler</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>Server</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>2080</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>ipc</span><span class=o>.</span><span class=n>Client</span><span class=o>.</span><span class=n>call</span><span class=p>(</span><span class=n>Client</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1471</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>ipc</span><span class=o>.</span><span class=n>Client</span><span class=o>.</span><span class=n>call</span><span class=p>(</span><span class=n>Client</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1408</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>ipc</span><span class=o>.</span><span class=n>ProtobufRpcEngine</span><span class=o>$</span><span class=n>Invoker</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>ProtobufRpcEngine</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>230</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>com</span><span class=o>.</span><span class=n>sun</span><span class=o>.</span><span class=n>proxy</span><span class=o>.$</span><span class=n>Proxy16</span><span class=o>.</span><span class=n>getAdditionalDatanode</span><span class=p>(</span><span class=n>Unknown</span> <span class=n>Source</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>protocolPB</span><span class=o>.</span><span class=n>ClientNamenodeProtocolTranslatorPB</span><span class=o>.</span><span class=n>getAdditionalDatanode</span><span class=p>(</span><span class=n>ClientNamenodeProtocolTranslatorPB</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>429</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>sun</span><span class=o>.</span><span class=n>reflect</span><span class=o>.</span><span class=n>NativeMethodAccessorImpl</span><span class=o>.</span><span class=n>invoke0</span><span class=p>(</span><span class=n>Native</span> <span class=n>Method</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>sun</span><span class=o>.</span><span class=n>reflect</span><span class=o>.</span><span class=n>NativeMethodAccessorImpl</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>NativeMethodAccessorImpl</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>62</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>sun</span><span class=o>.</span><span class=n>reflect</span><span class=o>.</span><span class=n>DelegatingMethodAccessorImpl</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>DelegatingMethodAccessorImpl</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>43</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>java</span><span class=o>.</span><span class=n>lang</span><span class=o>.</span><span class=n>reflect</span><span class=o>.</span><span class=n>Method</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>Method</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>498</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>retry</span><span class=o>.</span><span class=n>RetryInvocationHandler</span><span class=o>.</span><span class=n>invokeMethod</span><span class=p>(</span><span class=n>RetryInvocationHandler</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>256</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>retry</span><span class=o>.</span><span class=n>RetryInvocationHandler</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>RetryInvocationHandler</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>104</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>com</span><span class=o>.</span><span class=n>sun</span><span class=o>.</span><span class=n>proxy</span><span class=o>.$</span><span class=n>Proxy17</span><span class=o>.</span><span class=n>getAdditionalDatanode</span><span class=p>(</span><span class=n>Unknown</span> <span class=n>Source</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>sun</span><span class=o>.</span><span class=n>reflect</span><span class=o>.</span><span class=n>NativeMethodAccessorImpl</span><span class=o>.</span><span class=n>invoke0</span><span class=p>(</span><span class=n>Native</span> <span class=n>Method</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>sun</span><span class=o>.</span><span class=n>reflect</span><span class=o>.</span><span class=n>NativeMethodAccessorImpl</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>NativeMethodAccessorImpl</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>62</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>sun</span><span class=o>.</span><span class=n>reflect</span><span class=o>.</span><span class=n>DelegatingMethodAccessorImpl</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>DelegatingMethodAccessorImpl</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>43</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>java</span><span class=o>.</span><span class=n>lang</span><span class=o>.</span><span class=n>reflect</span><span class=o>.</span><span class=n>Method</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>Method</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>498</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>fs</span><span class=o>.</span><span class=n>HFileSystem</span><span class=o>$</span><span class=mf>1.</span><span class=n>invoke</span><span class=p>(</span><span class=n>HFileSystem</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>279</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>com</span><span class=o>.</span><span class=n>sun</span><span class=o>.</span><span class=n>proxy</span><span class=o>.$</span><span class=n>Proxy18</span><span class=o>.</span><span class=n>getAdditionalDatanode</span><span class=p>(</span><span class=n>Unknown</span> <span class=n>Source</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>addDatanode2ExistingPipeline</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1228</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>setupPipelineForAppendOrRecovery</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1404</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>processDatanodeError</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1119</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>622</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>13</span> <span class=mi>14</span><span class=p>:</span><span class=mi>47</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=mi>803</span> <span class=n>FATAL</span> <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node1</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.2</span><span class=p>:</span><span class=mi>60020</span><span class=p>]</span> <span class=n>regionserver</span><span class=o>.</span><span class=n>HRegionServer</span><span class=p>:</span> <span class=n>ABORTING</span> <span class=n>region</span> <span class=n>server</span> <span class=n>node1</span><span class=p>,</span><span class=mi>60020</span><span class=p>,</span><span class=mi>1519732610839</span><span class=p>:</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>YouAreDeadException</span><span class=p>:</span> <span class=n>Server</span> <span class=n>REPORT</span> <span class=n>rejected</span><span class=p>;</span> <span class=n>currently</span> <span class=n>processing</span> <span class=n>node1</span><span class=p>,</span><span class=mi>60020</span><span class=p>,</span><span class=mi>1519732610839</span> <span class=n>as</span> <span class=n>dead</span> <span class=n>server</span>
</span></span></code></pre></td></tr></table></div></div><p>从 14:47:49 开始， Hbase 没法和 Zookeeper 通信，连接时间超时。翻查 Zookeeper 的日志，发现Zookeeper 的日志有如下内容：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>2018-03-13 14:47:46,926 [myid:1] - INFO  [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588]
</span></span><span class=line><span class=cl>- Invalid session 0x161d6c1ae910002 for client /192.168.2.2:51611, probably expired
</span></span><span class=line><span class=cl>2018-03-13 14:47:49,612 [myid:1] - INFO  [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588]
</span></span><span class=line><span class=cl>- Invalid session 0x161d6c1ae910001 for client /192.168.2.2:51612, probably expired
</span></span></code></pre></td></tr></table></div></div><p>说明Hbase 和 ZooKeeper 的通信的确去了问题。连接出问题以后，集群就会认为 这个
Hbase 的节点出了故障，宕机，然后就把这个节点当作 <code>DeadNode</code>, 这个节点的
RegionServer 就下线了。</p><h3 id=node-master><span class=section-num>2.2</span> node-master<a hidden class=anchor aria-hidden=true href=#node-master>#</a></h3><p>现在再来看看node-master这台机器的日志</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>19</span><span class=p>,</span><span class=mi>986</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>main</span><span class=o>-</span><span class=n>SendThread</span><span class=p>(</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>:</span><span class=mi>2181</span><span class=p>)]</span> <span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>Unable</span> <span class=n>to</span> <span class=n>read</span> <span class=n>additional</span> <span class=n>data</span> <span class=n>from</span> <span class=n>server</span> <span class=n>sessionid</span> <span class=mh>0x361d65049260001</span><span class=p>,</span> <span class=n>likely</span> <span class=n>server</span> <span class=n>has</span> <span class=n>closed</span> <span class=n>socket</span><span class=p>,</span> <span class=n>closing</span> <span class=n>socket</span> <span class=n>connection</span> <span class=ow>and</span> <span class=n>attempting</span> <span class=n>reconnect</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>20</span><span class=p>,</span><span class=mi>841</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>main</span><span class=o>-</span><span class=n>SendThread</span><span class=p>(</span><span class=n>node1</span><span class=p>:</span><span class=mi>2181</span><span class=p>)]</span> <span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>Opening</span> <span class=n>socket</span> <span class=n>connection</span> <span class=n>to</span> <span class=n>server</span> <span class=n>node1</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.2</span><span class=p>:</span><span class=mf>2181.</span> <span class=n>Will</span> <span class=ow>not</span> <span class=n>attempt</span> <span class=n>to</span> <span class=n>authenticate</span> <span class=n>using</span> <span class=n>SASL</span> <span class=p>(</span><span class=n>unknown</span> <span class=n>error</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>43</span><span class=p>,</span><span class=mi>747</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>60020</span><span class=o>-</span><span class=n>SendThread</span><span class=p>(</span><span class=n>node1</span><span class=p>:</span><span class=mi>2181</span><span class=p>)]</span> <span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>Client</span> <span class=n>session</span> <span class=n>timed</span> <span class=n>out</span><span class=p>,</span> <span class=n>have</span> <span class=ow>not</span> <span class=n>heard</span> <span class=n>from</span> <span class=n>server</span> <span class=ow>in</span> <span class=mi>60019</span><span class=n>ms</span> <span class=k>for</span> <span class=n>sessionid</span> <span class=mh>0x161d65049590000</span><span class=p>,</span> <span class=n>closing</span> <span class=n>socket</span> <span class=n>connection</span> <span class=ow>and</span> <span class=n>attempting</span> <span class=n>reconnect</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>44</span><span class=p>,</span><span class=mi>574</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>60020</span><span class=o>-</span><span class=n>SendThread</span><span class=p>(</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>:</span><span class=mi>2181</span><span class=p>)]</span> <span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>Opening</span> <span class=n>socket</span> <span class=n>connection</span> <span class=n>to</span> <span class=n>server</span> <span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mf>2181.</span> <span class=n>Will</span> <span class=ow>not</span> <span class=n>attempt</span> <span class=n>to</span> <span class=n>authenticate</span> <span class=n>using</span> <span class=n>SASL</span> <span class=p>(</span><span class=n>unknown</span> <span class=n>error</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>44</span><span class=p>,</span><span class=mi>575</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>60020</span><span class=o>-</span><span class=n>SendThread</span><span class=p>(</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>:</span><span class=mi>2181</span><span class=p>)]</span> <span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>Socket</span> <span class=n>connection</span> <span class=n>established</span><span class=p>,</span> <span class=n>initiating</span> <span class=n>session</span><span class=p>,</span> <span class=n>client</span><span class=p>:</span> <span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>58042</span><span class=p>,</span> <span class=n>server</span><span class=p>:</span> <span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>2181</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>44</span><span class=p>,</span><span class=mi>577</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>60020</span><span class=o>-</span><span class=n>SendThread</span><span class=p>(</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>:</span><span class=mi>2181</span><span class=p>)]</span> <span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>Session</span> <span class=n>establishment</span> <span class=n>complete</span> <span class=n>on</span> <span class=n>server</span> <span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>2181</span><span class=p>,</span> <span class=n>sessionid</span> <span class=o>=</span> <span class=mh>0x161d65049590000</span><span class=p>,</span> <span class=n>negotiated</span> <span class=n>timeout</span> <span class=o>=</span> <span class=mi>90000</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>49</span><span class=p>,</span><span class=mi>625</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>main</span><span class=o>-</span><span class=n>SendThread</span><span class=p>(</span><span class=n>node1</span><span class=p>:</span><span class=mi>2181</span><span class=p>)]</span> <span class=n>zookeeper</span><span class=o>.</span><span class=n>ClientCnxn</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>Socket</span> <span class=n>connection</span> <span class=n>established</span><span class=p>,</span> <span class=n>initiating</span> <span class=n>session</span><span class=p>,</span> <span class=n>client</span><span class=p>:</span> <span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>46815</span><span class=p>,</span> <span class=n>server</span><span class=p>:</span> <span class=n>node1</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.2</span><span class=p>:</span><span class=mi>2181</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=mi>258</span> <span class=n>WARN</span>  <span class=p>[</span><span class=n>ResponseProcessor</span> <span class=k>for</span> <span class=n>block</span> <span class=n>BP</span><span class=o>-</span><span class=mi>1296874721</span><span class=o>-</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=o>-</span><span class=mi>1519712987003</span><span class=p>:</span>
</span></span><span class=line><span class=cl><span class=n>blk_1073747108_6286</span><span class=p>]</span> <span class=n>hdfs</span><span class=o>.</span><span class=n>DFSClient</span><span class=p>:</span> <span class=n>Slow</span> <span class=n>ReadProcessor</span> <span class=n>read</span> <span class=n>fields</span> <span class=n>took</span> <span class=mi>70070</span><span class=n>ms</span> <span class=p>(</span><span class=n>threshold</span><span class=o>=</span><span class=mi>30000</span><span class=n>ms</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>ack</span><span class=p>:</span> <span class=n>seqno</span><span class=p>:</span> <span class=o>-</span><span class=mi>2</span> <span class=n>reply</span><span class=p>:</span> <span class=mi>0</span> <span class=n>reply</span><span class=p>:</span> <span class=mi>1</span> <span class=n>downstreamAckTimeNanos</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span> <span class=n>targets</span><span class=p>:</span> <span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.2</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>4</span><span class=n>eb97418</span><span class=o>-</span><span class=n>f0a1</span><span class=o>-</span><span class=mi>45</span><span class=n>a7</span><span class=o>-</span><span class=n>b335</span><span class=o>-</span><span class=mi>83</span><span class=n>f77e4d6a7b</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=mi>259</span> <span class=n>WARN</span>  <span class=p>[</span><span class=n>ResponseProcessor</span> <span class=k>for</span> <span class=n>block</span> <span class=n>BP</span><span class=o>-</span><span class=mi>1296874721</span><span class=o>-</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=o>-</span><span class=mi>1519712987003</span><span class=p>:</span><span class=n>blk_1073747108_6286</span><span class=p>]</span> <span class=n>hdfs</span><span class=o>.</span><span class=n>DFSClient</span><span class=p>:</span> <span class=n>DFSOutputStream</span> <span class=n>ResponseProcessor</span> <span class=n>exception</span>  <span class=k>for</span> <span class=n>block</span> <span class=n>BP</span><span class=o>-</span><span class=mi>1296874721</span><span class=o>-</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=o>-</span><span class=mi>1519712987003</span><span class=p>:</span><span class=n>blk_1073747108_6286</span>
</span></span><span class=line><span class=cl><span class=n>java</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>IOException</span><span class=p>:</span> <span class=n>Bad</span> <span class=n>response</span> <span class=n>ERROR</span> <span class=k>for</span> <span class=n>block</span> <span class=n>BP</span><span class=o>-</span><span class=mi>1296874721</span><span class=o>-</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=o>-</span><span class=mi>1519712987003</span><span class=p>:</span><span class=n>blk_1073747108_6286</span> <span class=n>from</span> <span class=n>datanode</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.2</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>4</span><span class=n>eb97418</span><span class=o>-</span><span class=n>f0a1</span><span class=o>-</span><span class=mi>45</span><span class=n>a7</span><span class=o>-</span><span class=n>b335</span><span class=o>-</span><span class=mi>83</span><span class=n>f77e4d6a7b</span><span class=p>,</span><span class=n>DISK</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>$</span><span class=n>ResponseProcessor</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1002</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=mi>259</span> <span class=n>WARN</span>  <span class=p>[</span><span class=n>DataStreamer</span> <span class=k>for</span> <span class=n>file</span> <span class=o>/</span><span class=n>hbase</span><span class=o>-</span><span class=n>nemo</span><span class=o>/</span><span class=n>WALs</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>,</span><span class=mi>60020</span><span class=p>,</span><span class=mi>1519720160721</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>%</span><span class=mi>2</span><span class=n>C60020</span><span class=o>%</span><span class=mi>2</span><span class=n>C1519720160721</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=mi>1521509628323</span> <span class=n>block</span> <span class=n>BP</span><span class=o>-</span><span class=mi>1296874721</span><span class=o>-</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=o>-</span><span class=mi>1519712987003</span><span class=p>:</span><span class=n>blk_1073747108_6286</span><span class=p>]</span> <span class=n>hdfs</span><span class=o>.</span><span class=n>DFSClient</span><span class=p>:</span> <span class=n>Error</span> <span class=n>Recovery</span> <span class=k>for</span> <span class=n>block</span> <span class=n>BP</span><span class=o>-</span><span class=mi>1296874721</span><span class=o>-</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=o>-</span><span class=mi>1519712987003</span><span class=p>:</span><span class=n>blk_1073747108_6286</span> <span class=ow>in</span> <span class=n>pipeline</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.2</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>4</span><span class=n>eb97418</span><span class=o>-</span><span class=n>f0a1</span><span class=o>-</span><span class=mi>45</span><span class=n>a7</span><span class=o>-</span><span class=n>b335</span><span class=o>-</span><span class=mi>83</span><span class=n>f77e4d6a7b</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]:</span> <span class=n>bad</span> <span class=n>datanode</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.2</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>4</span><span class=n>eb97418</span><span class=o>-</span><span class=n>f0a1</span><span class=o>-</span><span class=mi>45</span><span class=n>a7</span><span class=o>-</span><span class=n>b335</span><span class=o>-</span><span class=mi>83</span><span class=n>f77e4d6a7b</span><span class=p>,</span><span class=n>DISK</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=mi>264</span> <span class=n>WARN</span>  <span class=p>[</span><span class=n>DataStreamer</span> <span class=k>for</span> <span class=n>file</span> <span class=o>/</span><span class=n>hbase</span><span class=o>-</span><span class=n>nemo</span><span class=o>/</span><span class=n>WALs</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>,</span><span class=mi>60020</span><span class=p>,</span><span class=mi>1519720160721</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>%</span><span class=mi>2</span><span class=n>C60020</span><span class=o>%</span><span class=mi>2</span><span class=n>C1519720160721</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=mi>1521509628323</span> <span class=n>block</span> <span class=n>BP</span><span class=o>-</span><span class=mi>1296874721</span><span class=o>-</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=o>-</span><span class=mi>1519712987003</span><span class=p>:</span><span class=n>blk_1073747108_6286</span><span class=p>]</span> <span class=n>hdfs</span><span class=o>.</span><span class=n>DFSClient</span><span class=p>:</span> <span class=n>DataStreamer</span> <span class=n>Exception</span>
</span></span><span class=line><span class=cl><span class=n>java</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>IOException</span><span class=p>:</span> <span class=n>Failed</span> <span class=n>to</span> <span class=n>replace</span> <span class=n>a</span> <span class=n>bad</span> <span class=n>datanode</span> <span class=n>on</span> <span class=n>the</span> <span class=n>existing</span> <span class=n>pipeline</span> <span class=n>due</span> <span class=n>to</span> <span class=n>no</span> <span class=n>more</span> <span class=n>good</span> <span class=n>datanodes</span> <span class=n>being</span> <span class=n>available</span> <span class=n>to</span> <span class=n>try</span><span class=o>.</span> <span class=p>(</span><span class=n>Nodes</span><span class=p>:</span> <span class=n>current</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]],</span> <span class=n>original</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]])</span><span class=o>.</span> <span class=n>The</span> <span class=n>current</span> <span class=n>failed</span> <span class=n>datanode</span> <span class=n>replacement</span> <span class=n>policy</span> <span class=n>is</span> <span class=n>DEFAULT</span><span class=p>,</span> <span class=ow>and</span> <span class=n>a</span> <span class=n>client</span> <span class=n>may</span> <span class=n>configure</span> <span class=n>this</span> <span class=n>via</span> <span class=s1>&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class=ow>in</span> <span class=n>its</span> <span class=n>configuration</span><span class=o>.</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>findNewDatanode</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1162</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>addDatanode2ExistingPipeline</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1236</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>setupPipelineForAppendOrRecovery</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1404</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>processDatanodeError</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1119</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>622</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=mi>265</span> <span class=n>WARN</span>  <span class=p>[</span><span class=n>sync</span><span class=o>.</span><span class=mi>4</span><span class=p>]</span> <span class=n>hdfs</span><span class=o>.</span><span class=n>DFSClient</span><span class=p>:</span> <span class=n>Error</span> <span class=k>while</span> <span class=n>syncing</span>
</span></span><span class=line><span class=cl><span class=n>java</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>IOException</span><span class=p>:</span> <span class=n>Failed</span> <span class=n>to</span> <span class=n>replace</span> <span class=n>a</span> <span class=n>bad</span> <span class=n>datanode</span> <span class=n>on</span> <span class=n>the</span> <span class=n>existing</span> <span class=n>pipeline</span> <span class=n>due</span> <span class=n>to</span> <span class=n>no</span> <span class=n>more</span> <span class=n>good</span> <span class=n>datanodes</span> <span class=n>being</span> <span class=n>available</span> <span class=n>to</span> <span class=n>try</span><span class=o>.</span> <span class=p>(</span><span class=n>Nodes</span><span class=p>:</span> <span class=n>current</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]],</span> <span class=n>original</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]])</span><span class=o>.</span> <span class=n>The</span> <span class=n>current</span> <span class=n>failed</span> <span class=n>datanode</span> <span class=n>replacement</span> <span class=n>policy</span> <span class=n>is</span> <span class=n>DEFAULT</span><span class=p>,</span> <span class=ow>and</span> <span class=n>a</span> <span class=n>client</span> <span class=n>may</span> <span class=n>configure</span> <span class=n>this</span> <span class=n>via</span> <span class=s1>&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class=ow>in</span> <span class=n>its</span> <span class=n>configuration</span><span class=o>.</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>findNewDatanode</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1162</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>addDatanode2ExistingPipeline</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1236</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>setupPipelineForAppendOrRecovery</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1404</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>processDatanodeError</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1119</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>622</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=mi>266</span> <span class=n>ERROR</span> <span class=p>[</span><span class=n>sync</span><span class=o>.</span><span class=mi>4</span><span class=p>]</span> <span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=p>:</span> <span class=n>Error</span> <span class=n>syncing</span><span class=p>,</span> <span class=n>request</span> <span class=n>close</span> <span class=n>of</span> <span class=n>WAL</span>
</span></span><span class=line><span class=cl><span class=n>java</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>IOException</span><span class=p>:</span> <span class=n>Failed</span> <span class=n>to</span> <span class=n>replace</span> <span class=n>a</span> <span class=n>bad</span> <span class=n>datanode</span> <span class=n>on</span> <span class=n>the</span> <span class=n>existing</span> <span class=n>pipeline</span> <span class=n>due</span> <span class=n>to</span> <span class=n>no</span> <span class=n>more</span> <span class=n>good</span> <span class=n>datanodes</span> <span class=n>being</span> <span class=n>available</span> <span class=n>to</span> <span class=n>try</span><span class=o>.</span> <span class=p>(</span><span class=n>Nodes</span><span class=p>:</span> <span class=n>current</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]],</span> <span class=n>original</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]])</span><span class=o>.</span> <span class=n>The</span> <span class=n>current</span> <span class=n>failed</span> <span class=n>datanode</span> <span class=n>replacement</span> <span class=n>policy</span> <span class=n>is</span> <span class=n>DEFAULT</span><span class=p>,</span> <span class=ow>and</span> <span class=n>a</span> <span class=n>client</span> <span class=n>may</span> <span class=n>configure</span> <span class=n>this</span> <span class=n>via</span> <span class=s1>&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class=ow>in</span> <span class=n>its</span> <span class=n>configuration</span><span class=o>.</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>findNewDatanode</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1162</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>addDatanode2ExistingPipeline</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1236</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>setupPipelineForAppendOrRecovery</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1404</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>processDatanodeError</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1119</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>622</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>12</span><span class=p>:</span><span class=mi>53</span><span class=p>,</span><span class=mi>266</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>sync</span><span class=o>.</span><span class=mi>4</span><span class=p>]</span> <span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=p>:</span> <span class=n>Slow</span> <span class=n>sync</span> <span class=n>cost</span><span class=p>:</span> <span class=mi>474</span> <span class=n>ms</span><span class=p>,</span> <span class=n>current</span> <span class=n>pipeline</span><span class=p>:</span> <span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>13</span><span class=p>:</span><span class=mi>05</span><span class=p>,</span><span class=mi>816</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mf>60020.</span><span class=n>logRoller</span><span class=p>]</span> <span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=p>:</span> <span class=n>Slow</span> <span class=n>sync</span> <span class=n>cost</span><span class=p>:</span> <span class=mi>12546</span> <span class=n>ms</span><span class=p>,</span> <span class=n>current</span> <span class=n>pipeline</span><span class=p>:</span> <span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>13</span><span class=p>:</span><span class=mi>05</span><span class=p>,</span><span class=mi>817</span> <span class=n>ERROR</span> <span class=p>[</span><span class=n>sync</span><span class=o>.</span><span class=mi>0</span><span class=p>]</span> <span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=p>:</span> <span class=n>Error</span> <span class=n>syncing</span><span class=p>,</span> <span class=n>request</span> <span class=n>close</span> <span class=n>of</span> <span class=n>WAL</span>
</span></span><span class=line><span class=cl><span class=n>java</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>IOException</span><span class=p>:</span> <span class=n>Failed</span> <span class=n>to</span> <span class=n>replace</span> <span class=n>a</span> <span class=n>bad</span> <span class=n>datanode</span> <span class=n>on</span> <span class=n>the</span> <span class=n>existing</span> <span class=n>pipeline</span> <span class=n>due</span> <span class=n>to</span> <span class=n>no</span> <span class=n>more</span> <span class=n>good</span> <span class=n>datanodes</span> <span class=n>being</span> <span class=n>available</span> <span class=n>to</span> <span class=n>try</span><span class=o>.</span> <span class=p>(</span><span class=n>Nodes</span><span class=p>:</span> <span class=n>current</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]],</span> <span class=n>original</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]])</span><span class=o>.</span> <span class=n>The</span> <span class=n>current</span> <span class=n>failed</span> <span class=n>datanode</span> <span class=n>replacement</span> <span class=n>policy</span> <span class=n>is</span> <span class=n>DEFAULT</span><span class=p>,</span> <span class=ow>and</span> <span class=n>a</span> <span class=n>client</span> <span class=n>may</span> <span class=n>configure</span> <span class=n>this</span> <span class=n>via</span> <span class=s1>&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class=ow>in</span> <span class=n>its</span> <span class=n>configuration</span><span class=o>.</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>findNewDatanode</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1162</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>addDatanode2ExistingPipeline</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1236</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>setupPipelineForAppendOrRecovery</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1404</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>processDatanodeError</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1119</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>622</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>13</span><span class=p>:</span><span class=mi>05</span><span class=p>,</span><span class=mi>817</span> <span class=n>ERROR</span> <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mf>60020.</span><span class=n>logRoller</span><span class=p>]</span> <span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=p>:</span> <span class=n>Failed</span> <span class=n>close</span> <span class=n>of</span> <span class=n>WAL</span> <span class=n>writer</span> <span class=n>hdfs</span><span class=p>:</span><span class=o>//</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>:</span><span class=mi>19000</span><span class=o>/</span><span class=n>hbase</span><span class=o>-</span><span class=n>nemo</span><span class=o>/</span><span class=n>WALs</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>,</span><span class=mi>60020</span><span class=p>,</span><span class=mi>1519720160721</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>%</span><span class=mi>2</span><span class=n>C60020</span><span class=o>%</span><span class=mi>2</span><span class=n>C1519720160721</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=mi>1521509628323</span><span class=p>,</span> <span class=n>unflushedEntries</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FailedSyncBeforeLogCloseException</span><span class=p>:</span> <span class=n>java</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>IOException</span><span class=p>:</span> <span class=n>Failed</span> <span class=n>to</span> <span class=n>replace</span> <span class=n>a</span> <span class=n>bad</span> <span class=n>datanode</span> <span class=n>on</span> <span class=n>the</span> <span class=n>existing</span> <span class=n>pipeline</span> <span class=n>due</span> <span class=n>to</span> <span class=n>no</span> <span class=n>more</span> <span class=n>good</span> <span class=n>datanodes</span> <span class=n>being</span> <span class=n>available</span> <span class=n>to</span> <span class=n>try</span><span class=o>.</span> <span class=p>(</span><span class=n>Nodes</span><span class=p>:</span> <span class=n>current</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]],</span> <span class=n>original</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]])</span><span class=o>.</span> <span class=n>The</span> <span class=n>current</span> <span class=n>failed</span> <span class=n>datanode</span> <span class=n>replacement</span> <span class=n>policy</span> <span class=n>is</span> <span class=n>DEFAULT</span><span class=p>,</span> <span class=ow>and</span> <span class=n>a</span> <span class=n>client</span> <span class=n>may</span> <span class=n>configure</span> <span class=n>this</span> <span class=n>via</span> <span class=s1>&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class=ow>in</span> <span class=n>its</span> <span class=n>configuration</span><span class=o>.</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=o>$</span><span class=n>SafePointZigZagLatch</span><span class=o>.</span><span class=n>waitSafePoint</span><span class=p>(</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1615</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>replaceWriter</span><span class=p>(</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>833</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>rollWriter</span><span class=p>(</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>699</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>LogRoller</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>LogRoller</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>148</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>java</span><span class=o>.</span><span class=n>lang</span><span class=o>.</span><span class=n>Thread</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=ne>Thread</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>748</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>Caused</span> <span class=n>by</span><span class=p>:</span> <span class=n>java</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>IOException</span><span class=p>:</span> <span class=n>Failed</span> <span class=n>to</span> <span class=n>replace</span> <span class=n>a</span> <span class=n>bad</span> <span class=n>datanode</span> <span class=n>on</span> <span class=n>the</span> <span class=n>existing</span> <span class=n>pipeline</span> <span class=n>due</span> <span class=n>to</span> <span class=n>no</span> <span class=n>more</span> <span class=n>good</span> <span class=n>datanodes</span> <span class=n>being</span> <span class=n>available</span> <span class=n>to</span> <span class=n>try</span><span class=o>.</span>
</span></span><span class=line><span class=cl><span class=p>(</span><span class=n>Nodes</span><span class=p>:</span> <span class=n>current</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]],</span>
</span></span><span class=line><span class=cl><span class=n>original</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span>
</span></span><span class=line><span class=cl><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]])</span><span class=o>.</span>
</span></span><span class=line><span class=cl><span class=n>The</span> <span class=n>current</span> <span class=n>failed</span> <span class=n>datanode</span> <span class=n>replacement</span> <span class=n>policy</span> <span class=n>is</span> <span class=n>DEFAULT</span><span class=p>,</span> <span class=ow>and</span> <span class=n>a</span> <span class=n>client</span> <span class=n>may</span> <span class=n>configure</span> <span class=n>this</span>
</span></span><span class=line><span class=cl><span class=n>via</span> <span class=s1>&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class=ow>in</span> <span class=n>its</span> <span class=n>configuration</span><span class=o>.</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>findNewDatanode</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1162</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>addDatanode2ExistingPipeline</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1236</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>setupPipelineForAppendOrRecovery</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1404</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>processDatanodeError</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1119</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>622</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>13</span><span class=p>:</span><span class=mi>05</span><span class=p>,</span><span class=mi>818</span> <span class=n>FATAL</span> <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mf>60020.</span><span class=n>logRoller</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>regionserver</span><span class=o>.</span><span class=n>HRegionServer</span><span class=p>:</span> <span class=n>ABORTING</span> <span class=n>region</span> <span class=n>server</span> <span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>,</span><span class=mi>60020</span><span class=p>,</span><span class=mi>1519720160721</span><span class=p>:</span> <span class=n>Failed</span> <span class=nb>log</span> <span class=n>close</span> <span class=ow>in</span> <span class=nb>log</span> <span class=n>roller</span>
</span></span><span class=line><span class=cl><span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FailedLogCloseException</span><span class=p>:</span> <span class=n>hdfs</span><span class=p>:</span><span class=o>//</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>:</span><span class=mi>19000</span><span class=o>/</span><span class=n>hbase</span><span class=o>-</span><span class=n>nemo</span><span class=o>/</span><span class=n>WALs</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=p>,</span><span class=mi>60020</span><span class=p>,</span><span class=mi>1519720160721</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>%</span><span class=mi>2</span><span class=n>C60020</span><span class=o>%</span><span class=mi>2</span><span class=n>C1519720160721</span><span class=o>.</span><span class=n>default</span><span class=o>.</span><span class=mi>1521509628323</span><span class=p>,</span> <span class=n>unflushedEntries</span><span class=o>=</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>replaceWriter</span><span class=p>(</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>882</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>rollWriter</span><span class=p>(</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>699</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>LogRoller</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>LogRoller</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>148</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>java</span><span class=o>.</span><span class=n>lang</span><span class=o>.</span><span class=n>Thread</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=ne>Thread</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>748</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>Caused</span> <span class=n>by</span><span class=p>:</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FailedSyncBeforeLogCloseException</span><span class=p>:</span> <span class=n>java</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>IOException</span><span class=p>:</span> <span class=n>Failed</span> <span class=n>to</span> <span class=n>replace</span> <span class=n>a</span> <span class=n>bad</span> <span class=n>datanode</span> <span class=n>on</span> <span class=n>the</span> <span class=n>existing</span> <span class=n>pipeline</span> <span class=n>due</span> <span class=n>to</span> <span class=n>no</span> <span class=n>more</span> <span class=n>good</span> <span class=n>datanodes</span> <span class=n>being</span> <span class=n>available</span> <span class=n>to</span> <span class=n>try</span><span class=o>.</span> <span class=p>(</span><span class=n>Nodes</span><span class=p>:</span> <span class=n>current</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]],</span> <span class=n>original</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]])</span><span class=o>.</span> <span class=n>The</span> <span class=n>current</span> <span class=n>failed</span> <span class=n>datanode</span> <span class=n>replacement</span> <span class=n>policy</span> <span class=n>is</span> <span class=n>DEFAULT</span><span class=p>,</span> <span class=ow>and</span> <span class=n>a</span> <span class=n>client</span> <span class=n>may</span> <span class=n>configure</span> <span class=n>this</span> <span class=n>via</span> <span class=s1>&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class=ow>in</span> <span class=n>its</span> <span class=n>configuration</span><span class=o>.</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=o>$</span><span class=n>SafePointZigZagLatch</span><span class=o>.</span><span class=n>waitSafePoint</span><span class=p>(</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1615</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hbase</span><span class=o>.</span><span class=n>regionserver</span><span class=o>.</span><span class=n>wal</span><span class=o>.</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>replaceWriter</span><span class=p>(</span><span class=n>FSHLog</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>833</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span> <span class=mi>3</span> <span class=n>more</span>
</span></span><span class=line><span class=cl><span class=n>Caused</span> <span class=n>by</span><span class=p>:</span> <span class=n>java</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>IOException</span><span class=p>:</span> <span class=n>Failed</span> <span class=n>to</span> <span class=n>replace</span> <span class=n>a</span> <span class=n>bad</span> <span class=n>datanode</span> <span class=n>on</span> <span class=n>the</span> <span class=n>existing</span> <span class=n>pipeline</span> <span class=n>due</span> <span class=n>to</span> <span class=n>no</span> <span class=n>more</span> <span class=n>good</span> <span class=n>datanodes</span> <span class=n>being</span> <span class=n>available</span> <span class=n>to</span> <span class=n>try</span><span class=o>.</span> <span class=p>(</span><span class=n>Nodes</span><span class=p>:</span> <span class=n>current</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]],</span> <span class=n>original</span><span class=o>=</span><span class=p>[</span><span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=mi>84998</span><span class=n>b22</span><span class=o>-</span><span class=mi>8294</span><span class=o>-</span><span class=mi>44</span><span class=n>ed</span><span class=o>-</span><span class=mi>90</span><span class=n>fd</span><span class=o>-</span><span class=mi>9</span><span class=n>c1a78d0f558</span><span class=p>,</span><span class=n>DISK</span><span class=p>],</span> <span class=n>DatanodeInfoWithStorage</span><span class=p>[</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.3</span><span class=p>:</span><span class=mi>50010</span><span class=p>,</span><span class=n>DS</span><span class=o>-</span><span class=n>d94668c9</span><span class=o>-</span><span class=mi>66</span><span class=n>f4</span><span class=o>-</span><span class=mi>40</span><span class=n>f6</span><span class=o>-</span><span class=n>b38f</span><span class=o>-</span><span class=mi>83</span><span class=n>f14b26c2b4</span><span class=p>,</span><span class=n>DISK</span><span class=p>]])</span><span class=o>.</span> <span class=n>The</span> <span class=n>current</span> <span class=n>failed</span> <span class=n>datanode</span> <span class=n>replacement</span> <span class=n>policy</span> <span class=n>is</span> <span class=n>DEFAULT</span><span class=p>,</span> <span class=ow>and</span> <span class=n>a</span> <span class=n>client</span> <span class=n>may</span> <span class=n>configure</span> <span class=n>this</span> <span class=n>via</span> <span class=s1>&#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39;</span> <span class=ow>in</span> <span class=n>its</span> <span class=n>configuration</span><span class=o>.</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>findNewDatanode</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1162</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>addDatanode2ExistingPipeline</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1236</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>setupPipelineForAppendOrRecovery</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1404</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>processDatanodeError</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>1119</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>at</span> <span class=n>org</span><span class=o>.</span><span class=n>apache</span><span class=o>.</span><span class=n>hadoop</span><span class=o>.</span><span class=n>hdfs</span><span class=o>.</span><span class=n>DFSOutputStream</span><span class=o>$</span><span class=n>DataStreamer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>DFSOutputStream</span><span class=o>.</span><span class=n>java</span><span class=p>:</span><span class=mi>622</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>13</span><span class=p>:</span><span class=mi>05</span><span class=p>,</span><span class=mi>818</span> <span class=n>FATAL</span> <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mf>60020.</span><span class=n>logRoller</span><span class=p>]</span> <span class=n>regionserver</span><span class=o>.</span><span class=n>HRegionServer</span><span class=p>:</span> <span class=n>RegionServer</span> <span class=n>abort</span><span class=p>:</span> <span class=n>loaded</span> <span class=n>coprocessors</span> <span class=n>are</span><span class=p>:</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=mi>2018</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>20</span> <span class=mi>10</span><span class=p>:</span><span class=mi>13</span><span class=p>:</span><span class=mi>05</span><span class=p>,</span><span class=mi>997</span> <span class=n>INFO</span>  <span class=p>[</span><span class=n>regionserver</span><span class=o>/</span><span class=n>node</span><span class=o>-</span><span class=n>master</span><span class=o>/</span><span class=mf>192.168</span><span class=o>.</span><span class=mf>2.1</span><span class=p>:</span><span class=mf>60020.</span><span class=n>logRoller</span><span class=p>]</span> <span class=n>regionserver</span><span class=o>.</span><span class=n>HRegionServer</span><span class=p>:</span> <span class=n>Dump</span> <span class=n>of</span> <span class=n>metrics</span> <span class=n>as</span> <span class=n>JSON</span> <span class=n>on</span> <span class=n>abort</span><span class=p>:</span>
</span></span></code></pre></td></tr></table></div></div><p>从上面的日志可以看到 node-master与node1机器通信，获取node1 的响应失败，认为node1 是 bad DataNode，接着集群想要把出现问题的DataNode 下掉，却发现没有多余DataNode 来替换， 紧接着在Syncing 时出错，关闭 WAL 失败, 最后就停掉了Region Server. 比较关键的时机如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>2018-03-20 10:12:53,265 WARN  [sync.4] hdfs.DFSClient: Error while syncing
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2018-03-20 10:12:53,266 ERROR [sync.4] wal.FSHLog: Error syncing, request close of WAL
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2018-03-20 10:13:05,817 ERROR [sync.0] wal.FSHLog: Error syncing, request close of WAL
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2018-03-20 10:13:06,397 ERROR [regionserver/node-master/192.168.2.1:60020] regionserver.HRegionServer: Shutdown / close of WAL failed: java.io.IOException: Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]], original=[DatanodeInfoWithStorage[192.168.2.1:50010,DS-84998b22-8294-44ed-90fd-9c1a78d0f558,DISK], DatanodeInfoWithStorage[192.168.2.3:50010,DS-d94668c9-66f4-40f6-b38f-83f14b26c2b4,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via &#39;dfs.client.block.write.replace-datanode-on-failure.policy&#39; in its configuration.
</span></span></code></pre></td></tr></table></div></div><p>期间HDFS 同步出错，尝试关闭WAL, 失败。失败的原因是无法用健康的节点替换出了问题的节点， 应该是健康的节点数太少了。最后在多次尝试关闭WAL都因为IOException 失败之后，
RegionServer 下线。只是为什么尝试关闭WAL 失败需要关闭Region Server 依然存疑。</p><h3 id=node2><span class=section-num>2.3</span> node2<a hidden class=anchor aria-hidden=true href=#node2>#</a></h3><p>node2 是Hbase 集群最后一台机器，当node2 倒下了，Hbase 就真的完全宕机了。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>2018-04-03 23:19:33,472 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.LogRoller: Aborting
</span></span><span class=line><span class=cl>java.io.IOException: cannot get log writer
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:365)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:724)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:689)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148)
</span></span><span class=line><span class=cl>    at java.lang.Thread.run(Thread.java:748)
</span></span><span class=line><span class=cl>Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/hbase-nemo/WALs/node2,60020,1519732668326/node2%2C60020%2C1519732668326.default.1522768773233. Name node is in safe mode.
</span></span><span class=line><span class=cl>Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use &#34;hdfs dfsadmin -safemode leave&#34; to turn safe mode off.
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1418)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2674)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2561)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:593)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.create(AuthorizationProviderProxyClientProtocol.java:111)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:393)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
</span></span><span class=line><span class=cl>    at java.security.AccessController.doPrivileged(Native Method)
</span></span><span class=line><span class=cl>    at javax.security.auth.Subject.doAs(Subject.java:422)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Client.call(Client.java:1471)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Client.call(Client.java:1408)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
</span></span><span class=line><span class=cl>    at com.sun.proxy.$Proxy16.create(Unknown Source)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
</span></span><span class=line><span class=cl>    at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
</span></span><span class=line><span class=cl>    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span></span><span class=line><span class=cl>    at java.lang.reflect.Method.invoke(Method.java:498)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
</span></span><span class=line><span class=cl>    at com.sun.proxy.$Proxy17.create(Unknown Source)
</span></span><span class=line><span class=cl>    at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
</span></span><span class=line><span class=cl>    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span></span><span class=line><span class=cl>    at java.lang.reflect.Method.invoke(Method.java:498)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
</span></span><span class=line><span class=cl>    at com.sun.proxy.$Proxy18.create(Unknown Source)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1897)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1738)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1698)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:450)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:446)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive(DistributedFileSystem.java:446)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1124)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1100)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.init(ProtobufLogWriter.java:90)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:361)
</span></span><span class=line><span class=cl>    ... 4 more
</span></span><span class=line><span class=cl>2018-04-03 23:19:33,501 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.HRegionServer: ABORTING region server node2,60020,1519732668326: IOE in log roller
</span></span><span class=line><span class=cl>java.io.IOException: cannot get log writer
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:365)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:724)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:689)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:148)
</span></span><span class=line><span class=cl>    at java.lang.Thread.run(Thread.java:748)
</span></span><span class=line><span class=cl>Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/hbase-nemo/WALs/node2,60020,1519732668326/node2%2C60020%2C1519732668326.default.1522768773233. Name node is in safe mode.
</span></span><span class=line><span class=cl>Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use &#34;hdfs dfsadmin -safemode leave&#34; to turn safe mode off.
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1418)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2674)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2561)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:593)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.create(AuthorizationProviderProxyClientProtocol.java:111)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:393)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:617)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1073)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2086)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2082)
</span></span><span class=line><span class=cl>    at java.security.AccessController.doPrivileged(Native Method)
</span></span><span class=line><span class=cl>    at javax.security.auth.Subject.doAs(Subject.java:422)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1693)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2080)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Client.call(Client.java:1471)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.Client.call(Client.java:1408)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
</span></span><span class=line><span class=cl>    at com.sun.proxy.$Proxy16.create(Unknown Source)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:296)
</span></span><span class=line><span class=cl>    at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
</span></span><span class=line><span class=cl>    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span></span><span class=line><span class=cl>    at java.lang.reflect.Method.invoke(Method.java:498)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:256)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
</span></span><span class=line><span class=cl>    at com.sun.proxy.$Proxy17.create(Unknown Source)
</span></span><span class=line><span class=cl>    at sun.reflect.GeneratedMethodAccessor30.invoke(Unknown Source)
</span></span><span class=line><span class=cl>    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
</span></span><span class=line><span class=cl>    at java.lang.reflect.Method.invoke(Method.java:498)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:279)
</span></span><span class=line><span class=cl>    at com.sun.proxy.$Proxy18.create(Unknown Source)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1897)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1738)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1698)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:450)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:446)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive(DistributedFileSystem.java:446)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1124)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1100)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter.init(ProtobufLogWriter.java:90)
</span></span><span class=line><span class=cl>    at org.apache.hadoop.hbase.wal.DefaultWALProvider.createWriter(DefaultWALProvider.java:361)
</span></span><span class=line><span class=cl>    ... 4 more
</span></span></code></pre></td></tr></table></div></div><p>可以看到上面的日志出现IO 出现异常，无法获取 <code>log writer</code>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>2018-04-03 23:19:33,472 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.LogRoller: Aborting
</span></span><span class=line><span class=cl>java.io.IOException: cannot get log writer
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2018-04-03 23:19:33,501 FATAL [regionserver/node2/192.168.2.3:60020.logRoller] regionserver.HRegionServer: ABORTING region server node2,60020,1519732668326: IOE in log roller
</span></span><span class=line><span class=cl>java.io.IOException: cannot get log writer
</span></span></code></pre></td></tr></table></div></div><p>而无法获取 <code>log writer</code>, 对日志进行写入的原因是：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot create file/hbase-nemo/WALs/node2,60020,1519732668326/node2%2C60020%2C1519732668326.default.1522768773233. Name node is in safe mode.
</span></span><span class=line><span class=cl>Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use &#34;hdfs dfsadmin -safemode leave&#34; to turn safe mode off.
</span></span></code></pre></td></tr></table></div></div><p>NameNode 进入了safe-mode, 关于safe-mode 的描述：
>During start up the NameNode loads the file system state from the fsimage and the edits log file. It then waits for DataNodes to report their blocks so that it does not prematurely start replicating the blocks though enough replicas already exist in the cluster. During this time NameNode stays in Safemode. Safemode for the NameNode is essentially a read-only mode for the HDFS cluster, where it does not allow any modifications to file system or blocks. Normally the NameNode leaves Safemode automatically after the DataNodes have reported that most file system blocks are available. If required, HDFS could be placed in Safemode explicitly using bin/hadoop dfsadmin -safemode command. NameNode front page shows whether Safemode is on or off. A more detailed description and configuration is maintained as JavaDoc for setSafeMode().</p><p>NameNode 进入safe-mode 的原因是因为 <code>node-master</code>这台Master 机器的磁盘被应用日志打满了，导 致 NameNode 进入了只读的 <code>safe-mode</code>. 因为NameNode 进入readonly 的safe-mode 就无 法写入日志, 所以 Hbase 在出现异常之后，就开始把Hbase 的信息 dump 出来，并关闭
Region Server, 导致整个Hbase 集群宕机。</p><p>对于<code>node2</code> Region Server 下线的原因，猜测是 NameNode 服务器的磁盘用完，导致NameNode 进入read-only 的safe-mode, 又因为Hbase 存储的核心之一是WAL(write-ahead-log, 预写日志),较长时间无法写入日志，最终导致 Region Server 下线。</p><h2 id=分析小结><span class=section-num>3</span> 分析小结<a hidden class=anchor aria-hidden=true href=#分析小结>#</a></h2><p>经过这样的一翻排查，可以得出结论，最开始 <code>node1</code> 因为Hbase 和 ZooKeeper 的通信出现问题， 被认为是问题节点，下线了Region Server；</p><p>一个星期之后，<code>node-master</code>这台机器在同步的时候 出现问题，想要关闭WAL, 但是却因为没有充足的健康节点来替换出现问题的<code>node1</code>, 导致关闭 WAL 失败，也下线了Region Server. <code>node2</code> 这台机器因为作为 NameNode 的<code>node-master</code>服务器的磁盘用 完，导致NameNode 进入read-only 的safe-mode, 又因为Hbase 存储的核心之一是
WAL(write-ahead-log, 预写日志),较长时间无法写入日志，最终导致 Region Server 下线。</p><h2 id=其他><span class=section-num>4</span> 其他<a hidden class=anchor aria-hidden=true href=#其他>#</a></h2><p>还有一个关键点是为什么Hbase 和Zookeeper 的连接超时，Zookeeper 的日志只是简单地说明：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>2018-03-13 14:47:46,926 [myid:1] - INFO  [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x161d6c1ae910002 for client /192.168.2.2:51611, probably expired
</span></span><span class=line><span class=cl>2018-03-13 14:47:49,612 [myid:1] - INFO  [QuorumPeer[myid=1]/0.0.0.0:2181:ZooKeeperServer@588] - Invalid session 0x161d6c1ae910001 for client /192.168.2.2:51612, probably expired
</span></span></code></pre></td></tr></table></div></div><p>为什么 session 会无效，日志并没有给出说明，个人猜测可能是因为在部署了 Hbase/Zookeeper 的服务器上还部署了应用。</p><p>应用或者是Hbase 导致的长GC 导致ZooKeeper 停顿，并且导致session 超时无效。</p><h2 id=结语><span class=section-num>5</span> 结语<a hidden class=anchor aria-hidden=true href=#结语>#</a></h2><p>和同事交流之后，觉得以上的分析只是基于日志的猜测，可能Hbase 宕机的原因正如我所说， 或者另有原因，所以现在最关键的措施是加上对Hbase 的各种监控。</p><p>在Hbase 宕机的时候， 参考日志和详细的监控，比如连接数，CPU 使用率，内存，集群负载情况，每个节点情况。不然再遇到一次宕机，还是只能看日志，猜原因。</p><p>话分两头，现在的分析主要是基于Hbase 和ZooKeeper 的日志进行分析，简而言之就是捞日 志，查看信息; 捞日志，查看信息；通过工具找出日志中隐藏的关键时机，然后对时机前后发生的事情进行分析，这也是一个有趣的过程。</p><p>只是从1G 多的日志里面找出想要的内容，也不是一个容易的过程。</p><div center class=qr-container><img src=/ox-hugo/qrcode_gh_e06d750e626f_1.jpg alt=qrcode_gh_e06d750e626f_1.jpg width=160px height=160px center=t class=qr-container>
公号同步更新，欢迎关注👻</div></div><footer class=post-footer><ul class=post-tags><li><a href=https://ramsayleung.github.io/zh/tags/hbase/>hbase</a></li></ul><nav class=paginav><a class=prev href=https://ramsayleung.github.io/zh/post/2018/lsof_cant_identify_protocol/><span class=title>« 上一页</span><br><span>lsof can't identify protocol</span>
</a><a class=next href=https://ramsayleung.github.io/zh/post/2018/store_cluster_migrate2/><span class=title>下一页 »</span><br><span>记存储集群的一次迁移过程（下）</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 记一次Hbase 宕机原因分析 on x" href="https://x.com/intent/tweet/?text=%e8%ae%b0%e4%b8%80%e6%ac%a1Hbase%20%e5%ae%95%e6%9c%ba%e5%8e%9f%e5%9b%a0%e5%88%86%e6%9e%90&amp;url=https%3a%2f%2framsayleung.github.io%2fzh%2fpost%2f2018%2fhbase_crash%2f&amp;hashtags=hbase"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 记一次Hbase 宕机原因分析 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2framsayleung.github.io%2fzh%2fpost%2f2018%2fhbase_crash%2f&amp;title=%e8%ae%b0%e4%b8%80%e6%ac%a1Hbase%20%e5%ae%95%e6%9c%ba%e5%8e%9f%e5%9b%a0%e5%88%86%e6%9e%90&amp;summary=%e8%ae%b0%e4%b8%80%e6%ac%a1Hbase%20%e5%ae%95%e6%9c%ba%e5%8e%9f%e5%9b%a0%e5%88%86%e6%9e%90&amp;source=https%3a%2f%2framsayleung.github.io%2fzh%2fpost%2f2018%2fhbase_crash%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 记一次Hbase 宕机原因分析 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2framsayleung.github.io%2fzh%2fpost%2f2018%2fhbase_crash%2f&title=%e8%ae%b0%e4%b8%80%e6%ac%a1Hbase%20%e5%ae%95%e6%9c%ba%e5%8e%9f%e5%9b%a0%e5%88%86%e6%9e%90"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 记一次Hbase 宕机原因分析 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2framsayleung.github.io%2fzh%2fpost%2f2018%2fhbase_crash%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 记一次Hbase 宕机原因分析 on whatsapp" href="https://api.whatsapp.com/send?text=%e8%ae%b0%e4%b8%80%e6%ac%a1Hbase%20%e5%ae%95%e6%9c%ba%e5%8e%9f%e5%9b%a0%e5%88%86%e6%9e%90%20-%20https%3a%2f%2framsayleung.github.io%2fzh%2fpost%2f2018%2fhbase_crash%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 记一次Hbase 宕机原因分析 on telegram" href="https://telegram.me/share/url?text=%e8%ae%b0%e4%b8%80%e6%ac%a1Hbase%20%e5%ae%95%e6%9c%ba%e5%8e%9f%e5%9b%a0%e5%88%86%e6%9e%90&amp;url=https%3a%2f%2framsayleung.github.io%2fzh%2fpost%2f2018%2fhbase_crash%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 记一次Hbase 宕机原因分析 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%e8%ae%b0%e4%b8%80%e6%ac%a1Hbase%20%e5%ae%95%e6%9c%ba%e5%8e%9f%e5%9b%a0%e5%88%86%e6%9e%90&u=https%3a%2f%2framsayleung.github.io%2fzh%2fpost%2f2018%2fhbase_crash%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><section><h2>Comments</h2><div id=comments-giscus></div></section><script type=text/javascript>function getCurrentTheme(){return document.documentElement.getAttribute("data-theme")||document.body.classList.contains("dark")?"dark":"light"}function setGiscusTheme(e=!1){const s=e?"dark":"light";var n,t=document.querySelector(".giscus-frame");t&&(n=new URL(t.src),n.searchParams.set("theme",s),t.src=n.toString())}function loadComment(e=!1){const n="zh"=="zh",t=document.getElementById("comments-giscus");if(t!==null&&!t.hasAttribute("data-giscus-loaded")){console.log("Initial giscus load");const s=document.createElement("script");s.setAttribute("src","https://giscus.app/client.js"),s.setAttribute("data-repo","ramsayleung/comment"),s.setAttribute("data-repo-id","MDEwOlJlcG9zaXRvcnkzMDk2NjQ1NDk="),s.setAttribute("data-category","General"),s.setAttribute("data-category-id","DIC_kwDOEnUbJc4Cltnz"),s.setAttribute("data-mapping","pathname"),s.setAttribute("data-strict","0"),s.setAttribute("data-reactions-enabled","1"),s.setAttribute("data-emit-metadata","0"),s.setAttribute("data-input-position","bottom"),s.setAttribute("data-theme",e?"dark":"light"),s.setAttribute("crossorigin","anonymous"),s.setAttribute("data-lang",n?"zh-CN":"en"),s.setAttribute("async","true"),t.appendChild(s),t.setAttribute("data-giscus-loaded","true")}}let currentTheme=getCurrentTheme();loadComment(currentTheme==="dark");const themeObserver=new MutationObserver(e=>{e.forEach(e=>{if(e.type==="attributes"&&e.attributeName==="class"){const e=getCurrentTheme();e!==currentTheme&&(currentTheme=e,setGiscusTheme(currentTheme==="dark"))}})});themeObserver.observe(document.body,{attributes:!0,attributeFilter:["class"]})</script></article></main><footer class=footer><span>See this site&rsquo;s source code <a href=https://github.com/ramsayleung/ramsayleung.github.io>here</a>, licensed under GPLv3 ·</span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ==" crossorigin=anonymous referrerpolicy=no-referrer></script><script>const images=Array.from(document.querySelectorAll(".post-content img"));images.forEach(e=>{mediumZoom(e,{margin:0,scrollOffset:40,container:null,template:null})})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>